{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import regularizers\n",
    "# from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "#                                     Add, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "class Autoencoder:\n",
    "    def __init__(self):\n",
    "        self.encoder_model = None\n",
    "        self.model = None\n",
    "        return\n",
    "    \n",
    "    def build_simple_ae(self, input_dim, encoding_dim):\n",
    "        input_layer = Input(shape=(input_dim,))\n",
    "        encoder_output = Dense(encoding_dim, activation='relu') (input_layer)\n",
    "        self.encoder_model = Model(input_layer, encoder_output)\n",
    "        decoder_output = Dense(input_dim, activation='sigmoid') (encoder_output)\n",
    "        self.model = Model(input_layer, decoder_output)\n",
    "        self.model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "        return\n",
    "    \n",
    "    def build_sparse_ae(self, input_dim, encoding_dim):\n",
    "        input_layer = Input(shape=(input_dim,))\n",
    "        encoder_output = Dense(encoding_dim, activation='relu',activity_regularizer=regularizers.l1(10e-5)) (input_layer)\n",
    "        self.encoder_model = Model(input_layer, encoder_output)\n",
    "        decoder_output = Dense(input_dim, activation='sigmoid') (encoder_output)\n",
    "        self.model = Model(input_layer, decoder_output)\n",
    "        self.model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "        return\n",
    "    \n",
    "    def build_deep_ae(self, input_dim, encoding_dim, opt):\n",
    "        input_layer = Input(shape=(input_dim,))\n",
    "        \n",
    "        hidden_one = Dense(encoding_dim*4, activation='relu') (input_layer)\n",
    "        hidden_two = Dense(encoding_dim*2, activation='relu') (hidden_one)\n",
    "        encoder_output = Dense(encoding_dim, activation='relu') (hidden_two)\n",
    "        self.encoder_model = Model(input_layer, encoder_output)\n",
    "        \n",
    "        hidden_three = Dense(encoding_dim*2, activation='relu') (encoder_output)\n",
    "        hidden_four = Dense(encoding_dim*4, activation='relu') (hidden_three)\n",
    "        decoder_output = Dense(input_dim, activation='sigmoid') (hidden_four)\n",
    "        self.model = Model(input_layer, decoder_output)\n",
    "        \n",
    "        self.model.compile(optimizer=opt, loss='binary_crossentropy', )\n",
    "        return\n",
    "    \n",
    "    def build_conv_ae(self, input_dims, encoding_dim):\n",
    "        input_layer = Input(shape=input_dims)\n",
    "        conv_one = Conv2D(16, (3,3), activation='relu', padding='same') (input_layer)\n",
    "        pool_one = MaxPooling2D((2,2), padding='same') (conv_one)\n",
    "        conv_two = Conv2D(8, (3,3), activation='relu', padding='same') (pool_one)\n",
    "        pool_two = MaxPooling2D((2,2), padding='same') (conv_two)\n",
    "        conv_three = Conv2D(8, (3,3), activation='relu', padding='same') (pool_two)\n",
    "        encoder_output = MaxPooling2D((2,2), padding='same') (conv_three)\n",
    "        self.encoder_model = Model(input_layer, encoder_output)\n",
    "        \n",
    "        conv_four = Conv2D(8, (3,3), activation='relu', padding='same') (encoder_output)\n",
    "        upsamp_one = UpSampling2D((2,2)) (conv_four)\n",
    "        conv_five = Conv2D(8, (3,3), activation='relu', padding='same') (upsamp_one)\n",
    "        upsamp_two = UpSampling2D((2,2)) (conv_five)\n",
    "        conv_six = Conv2D(16, (3,3), activation='relu') (upsamp_two)\n",
    "        upsamp_three = UpSampling2D((2,2)) (conv_six)\n",
    "        decoder_output = Conv2D(1, (3,3), activation='sigmoid', padding='same') (upsamp_three)\n",
    "        self.model = Model(input_layer, decoder_output)\n",
    "        \n",
    "        self.model.compile(optimizer='adagrad', loss='binary_crossentropy')\n",
    "        return\n",
    "    \n",
    "    def load(self, model_file, encoder_model_file):\n",
    "        self.encoder_model = load_model(encoder_model_file)\n",
    "        self.model = load_model(model_file)\n",
    "        return\n",
    "    \n",
    "    def train(self, train_input, train_output,\n",
    "             val_input, val_output,\n",
    "             epochs=50,\n",
    "             batch_size=256,\n",
    "             shuffle=True):\n",
    "        history = self.model.fit(train_input, train_output,\n",
    "                      epochs=epochs, batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(val_input, val_output),\n",
    "                      )\n",
    "        return history\n",
    "    \n",
    "    def encoder_predict(self, test_input):\n",
    "        return self.encoder_model.predict(test_input)\n",
    "    \n",
    "    def predict(self, test_input):\n",
    "        return self.model.predict(test_input)\n",
    "    \n",
    "    def save(self, model_file, encoder_model_file):\n",
    "        self.model.save(model_file)\n",
    "        self.encoder_model.save(encoder_model_file)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.datasets import cifar10\n",
    "# from tensorflow.keras import optimizers\n",
    "# import numpy as np\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# print (x_train.shape)\n",
    "# print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_in = open(\"model-features/cbir-resnet-features.pickle\", \"rb\")\n",
    "features = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"model-features/cbir-resnet-features-test.pickle\", \"rb\")\n",
    "features_test = pickle.load(pickle_in)\n",
    "\n",
    "print (features.shape)\n",
    "print (features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jalanin cell ini kalo ga ada pickle\n",
    "\n",
    "# feature_extractor = load_model('model-features/features.h5', compile=False)\n",
    "# features = feature_extractor.predict(x_train)\n",
    "# pickle_out = open(\"model-features/cbir-resnet-features.pickle\", \"wb\")\n",
    "# pickle.dump(features, pickle_out)\n",
    "# pickle_out.close()\n",
    "\n",
    "# features_test = feature_extractor.predict(x_test)\n",
    "# pickle_out = open(\"model-features/cbir-resnet-features-test.pickle\", \"wb\")\n",
    "# pickle.dump(features_test, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.6974 - val_loss: 0.6862\n",
      "Epoch 2/250\n",
      "3125/3125 [==============================] - 3s 976us/step - loss: 0.6833 - val_loss: 0.6714\n",
      "Epoch 3/250\n",
      "3125/3125 [==============================] - 3s 988us/step - loss: 0.6681 - val_loss: 0.6562\n",
      "Epoch 4/250\n",
      "3125/3125 [==============================] - 3s 860us/step - loss: 0.6526 - val_loss: 0.6409\n",
      "Epoch 5/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.6369 - val_loss: 0.6257\n",
      "Epoch 6/250\n",
      "3125/3125 [==============================] - 3s 871us/step - loss: 0.6213 - val_loss: 0.6102\n",
      "Epoch 7/250\n",
      "3125/3125 [==============================] - 3s 834us/step - loss: 0.6058 - val_loss: 0.5948\n",
      "Epoch 8/250\n",
      "3125/3125 [==============================] - 3s 842us/step - loss: 0.5898 - val_loss: 0.5793\n",
      "Epoch 9/250\n",
      "3125/3125 [==============================] - 3s 842us/step - loss: 0.5744 - val_loss: 0.5636\n",
      "Epoch 10/250\n",
      "3125/3125 [==============================] - 3s 845us/step - loss: 0.5583 - val_loss: 0.5479\n",
      "Epoch 11/250\n",
      "3125/3125 [==============================] - 3s 853us/step - loss: 0.5424 - val_loss: 0.5321\n",
      "Epoch 12/250\n",
      "3125/3125 [==============================] - 3s 847us/step - loss: 0.5264 - val_loss: 0.5165\n",
      "Epoch 13/250\n",
      "3125/3125 [==============================] - 3s 839us/step - loss: 0.5107 - val_loss: 0.5009\n",
      "Epoch 14/250\n",
      "3125/3125 [==============================] - 3s 997us/step - loss: 0.4949 - val_loss: 0.4853\n",
      "Epoch 15/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.4795 - val_loss: 0.4697\n",
      "Epoch 16/250\n",
      "3125/3125 [==============================] - 3s 851us/step - loss: 0.4636 - val_loss: 0.4543\n",
      "Epoch 17/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.4483 - val_loss: 0.4395\n",
      "Epoch 18/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.4336 - val_loss: 0.4252\n",
      "Epoch 19/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.4192 - val_loss: 0.4115\n",
      "Epoch 20/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.4057 - val_loss: 0.3987\n",
      "Epoch 21/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.3929 - val_loss: 0.3866\n",
      "Epoch 22/250\n",
      "3125/3125 [==============================] - 3s 801us/step - loss: 0.3810 - val_loss: 0.3752\n",
      "Epoch 23/250\n",
      "3125/3125 [==============================] - 3s 809us/step - loss: 0.3697 - val_loss: 0.3645\n",
      "Epoch 24/250\n",
      "3125/3125 [==============================] - 3s 840us/step - loss: 0.3592 - val_loss: 0.3545\n",
      "Epoch 25/250\n",
      "3125/3125 [==============================] - 3s 845us/step - loss: 0.3493 - val_loss: 0.3453\n",
      "Epoch 26/250\n",
      "3125/3125 [==============================] - 3s 838us/step - loss: 0.3401 - val_loss: 0.3368\n",
      "Epoch 27/250\n",
      "3125/3125 [==============================] - 3s 843us/step - loss: 0.3319 - val_loss: 0.3289\n",
      "Epoch 28/250\n",
      "3125/3125 [==============================] - 3s 824us/step - loss: 0.3240 - val_loss: 0.3218\n",
      "Epoch 29/250\n",
      "3125/3125 [==============================] - 3s 877us/step - loss: 0.3172 - val_loss: 0.3154\n",
      "Epoch 30/250\n",
      "3125/3125 [==============================] - 3s 833us/step - loss: 0.3109 - val_loss: 0.3096\n",
      "Epoch 31/250\n",
      "3125/3125 [==============================] - 3s 859us/step - loss: 0.3052 - val_loss: 0.3045\n",
      "Epoch 32/250\n",
      "3125/3125 [==============================] - 3s 932us/step - loss: 0.3000 - val_loss: 0.2998\n",
      "Epoch 33/250\n",
      "3125/3125 [==============================] - 3s 948us/step - loss: 0.2953 - val_loss: 0.2955\n",
      "Epoch 34/250\n",
      "3125/3125 [==============================] - 3s 931us/step - loss: 0.2912 - val_loss: 0.2916\n",
      "Epoch 35/250\n",
      "3125/3125 [==============================] - 3s 862us/step - loss: 0.2871 - val_loss: 0.2880\n",
      "Epoch 36/250\n",
      "3125/3125 [==============================] - 3s 853us/step - loss: 0.2835 - val_loss: 0.2847\n",
      "Epoch 37/250\n",
      "3125/3125 [==============================] - 3s 984us/step - loss: 0.2802 - val_loss: 0.2815\n",
      "Epoch 38/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.2770 - val_loss: 0.2786\n",
      "Epoch 39/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.2740 - val_loss: 0.2758\n",
      "Epoch 40/250\n",
      "3125/3125 [==============================] - 3s 984us/step - loss: 0.2711 - val_loss: 0.2732\n",
      "Epoch 41/250\n",
      "3125/3125 [==============================] - 3s 896us/step - loss: 0.2683 - val_loss: 0.2706\n",
      "Epoch 42/250\n",
      "3125/3125 [==============================] - 3s 859us/step - loss: 0.2657 - val_loss: 0.2682\n",
      "Epoch 43/250\n",
      "3125/3125 [==============================] - 3s 841us/step - loss: 0.2632 - val_loss: 0.2658\n",
      "Epoch 44/250\n",
      "3125/3125 [==============================] - 3s 851us/step - loss: 0.2607 - val_loss: 0.2635\n",
      "Epoch 45/250\n",
      "3125/3125 [==============================] - 3s 872us/step - loss: 0.2584 - val_loss: 0.2612\n",
      "Epoch 46/250\n",
      "3125/3125 [==============================] - 3s 856us/step - loss: 0.2560 - val_loss: 0.2590\n",
      "Epoch 47/250\n",
      "3125/3125 [==============================] - 3s 841us/step - loss: 0.2538 - val_loss: 0.2568\n",
      "Epoch 48/250\n",
      "3125/3125 [==============================] - 3s 861us/step - loss: 0.2515 - val_loss: 0.2547\n",
      "Epoch 49/250\n",
      "3125/3125 [==============================] - 3s 876us/step - loss: 0.2492 - val_loss: 0.2526\n",
      "Epoch 50/250\n",
      "3125/3125 [==============================] - 3s 849us/step - loss: 0.2470 - val_loss: 0.2505\n",
      "Epoch 51/250\n",
      "3125/3125 [==============================] - 3s 840us/step - loss: 0.2449 - val_loss: 0.2484\n",
      "Epoch 52/250\n",
      "3125/3125 [==============================] - 3s 858us/step - loss: 0.2425 - val_loss: 0.2463\n",
      "Epoch 53/250\n",
      "3125/3125 [==============================] - 3s 828us/step - loss: 0.2403 - val_loss: 0.2442\n",
      "Epoch 54/250\n",
      "3125/3125 [==============================] - 3s 839us/step - loss: 0.2381 - val_loss: 0.2421\n",
      "Epoch 55/250\n",
      "3125/3125 [==============================] - 3s 830us/step - loss: 0.2359 - val_loss: 0.2401\n",
      "Epoch 56/250\n",
      "3125/3125 [==============================] - 3s 833us/step - loss: 0.2338 - val_loss: 0.2380\n",
      "Epoch 57/250\n",
      "3125/3125 [==============================] - 3s 887us/step - loss: 0.2317 - val_loss: 0.2359\n",
      "Epoch 58/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.2293 - val_loss: 0.2339\n",
      "Epoch 59/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.2274 - val_loss: 0.2318\n",
      "Epoch 60/250\n",
      "3125/3125 [==============================] - 3s 970us/step - loss: 0.2251 - val_loss: 0.2298\n",
      "Epoch 61/250\n",
      "3125/3125 [==============================] - 3s 873us/step - loss: 0.2230 - val_loss: 0.2277\n",
      "Epoch 62/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.2206 - val_loss: 0.2257\n",
      "Epoch 63/250\n",
      "3125/3125 [==============================] - 3s 918us/step - loss: 0.2187 - val_loss: 0.2236\n",
      "Epoch 64/250\n",
      "3125/3125 [==============================] - 3s 923us/step - loss: 0.2165 - val_loss: 0.2216\n",
      "Epoch 65/250\n",
      "3125/3125 [==============================] - 3s 908us/step - loss: 0.2141 - val_loss: 0.2195\n",
      "Epoch 66/250\n",
      "3125/3125 [==============================] - 3s 984us/step - loss: 0.2120 - val_loss: 0.2175\n",
      "Epoch 67/250\n",
      "3125/3125 [==============================] - 3s 895us/step - loss: 0.2098 - val_loss: 0.2154\n",
      "Epoch 68/250\n",
      "3125/3125 [==============================] - 3s 894us/step - loss: 0.2077 - val_loss: 0.2134\n",
      "Epoch 69/250\n",
      "3125/3125 [==============================] - 3s 892us/step - loss: 0.2057 - val_loss: 0.2113\n",
      "Epoch 70/250\n",
      "3125/3125 [==============================] - 3s 929us/step - loss: 0.2031 - val_loss: 0.2093\n",
      "Epoch 71/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.2011 - val_loss: 0.2073\n",
      "Epoch 72/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.1990 - val_loss: 0.2052\n",
      "Epoch 73/250\n",
      "3125/3125 [==============================] - 3s 978us/step - loss: 0.1968 - val_loss: 0.2032\n",
      "Epoch 74/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1945 - val_loss: 0.2012\n",
      "Epoch 75/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1924 - val_loss: 0.1991\n",
      "Epoch 76/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1903 - val_loss: 0.1971\n",
      "Epoch 77/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1881 - val_loss: 0.1951\n",
      "Epoch 78/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1858 - val_loss: 0.1930\n",
      "Epoch 79/250\n",
      "3125/3125 [==============================] - 3s 950us/step - loss: 0.1839 - val_loss: 0.1910\n",
      "Epoch 80/250\n",
      "3125/3125 [==============================] - 3s 919us/step - loss: 0.1817 - val_loss: 0.1890\n",
      "Epoch 81/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1795 - val_loss: 0.1870\n",
      "Epoch 82/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1773 - val_loss: 0.1850\n",
      "Epoch 83/250\n",
      "3125/3125 [==============================] - 3s 961us/step - loss: 0.1752 - val_loss: 0.1829\n",
      "Epoch 84/250\n",
      "3125/3125 [==============================] - 3s 959us/step - loss: 0.1729 - val_loss: 0.1809\n",
      "Epoch 85/250\n",
      "3125/3125 [==============================] - 3s 968us/step - loss: 0.1710 - val_loss: 0.1789\n",
      "Epoch 86/250\n",
      "3125/3125 [==============================] - 3s 987us/step - loss: 0.1688 - val_loss: 0.1769\n",
      "Epoch 87/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1667 - val_loss: 0.1749\n",
      "Epoch 88/250\n",
      "3125/3125 [==============================] - 3s 999us/step - loss: 0.1646 - val_loss: 0.1730\n",
      "Epoch 89/250\n",
      "3125/3125 [==============================] - 3s 997us/step - loss: 0.1624 - val_loss: 0.1710\n",
      "Epoch 90/250\n",
      "3125/3125 [==============================] - 3s 897us/step - loss: 0.1604 - val_loss: 0.1691\n",
      "Epoch 91/250\n",
      "3125/3125 [==============================] - 3s 875us/step - loss: 0.1584 - val_loss: 0.1671\n",
      "Epoch 92/250\n",
      "3125/3125 [==============================] - 3s 865us/step - loss: 0.1563 - val_loss: 0.1652\n",
      "Epoch 93/250\n",
      "3125/3125 [==============================] - 3s 874us/step - loss: 0.1541 - val_loss: 0.1633\n",
      "Epoch 94/250\n",
      "3125/3125 [==============================] - 3s 887us/step - loss: 0.1523 - val_loss: 0.1614\n",
      "Epoch 95/250\n",
      "3125/3125 [==============================] - 3s 886us/step - loss: 0.1500 - val_loss: 0.1595\n",
      "Epoch 96/250\n",
      "3125/3125 [==============================] - 3s 923us/step - loss: 0.1480 - val_loss: 0.1576\n",
      "Epoch 97/250\n",
      "3125/3125 [==============================] - 3s 926us/step - loss: 0.1462 - val_loss: 0.1558\n",
      "Epoch 98/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1441 - val_loss: 0.1539\n",
      "Epoch 99/250\n",
      "3125/3125 [==============================] - 3s 977us/step - loss: 0.1424 - val_loss: 0.1521\n",
      "Epoch 100/250\n",
      "3125/3125 [==============================] - 3s 870us/step - loss: 0.1402 - val_loss: 0.1503\n",
      "Epoch 101/250\n",
      "3125/3125 [==============================] - 3s 997us/step - loss: 0.1383 - val_loss: 0.1485\n",
      "Epoch 102/250\n",
      "3125/3125 [==============================] - 3s 992us/step - loss: 0.1362 - val_loss: 0.1468\n",
      "Epoch 103/250\n",
      "3125/3125 [==============================] - 3s 981us/step - loss: 0.1345 - val_loss: 0.1450\n",
      "Epoch 104/250\n",
      "3125/3125 [==============================] - 3s 968us/step - loss: 0.1325 - val_loss: 0.1433\n",
      "Epoch 105/250\n",
      "3125/3125 [==============================] - 3s 970us/step - loss: 0.1308 - val_loss: 0.1416\n",
      "Epoch 106/250\n",
      "3125/3125 [==============================] - 3s 981us/step - loss: 0.1290 - val_loss: 0.1398\n",
      "Epoch 107/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1271 - val_loss: 0.1381\n",
      "Epoch 108/250\n",
      "3125/3125 [==============================] - 3s 984us/step - loss: 0.1253 - val_loss: 0.1365\n",
      "Epoch 109/250\n",
      "3125/3125 [==============================] - 3s 903us/step - loss: 0.1236 - val_loss: 0.1348\n",
      "Epoch 110/250\n",
      "3125/3125 [==============================] - 3s 953us/step - loss: 0.1218 - val_loss: 0.1332\n",
      "Epoch 111/250\n",
      "3125/3125 [==============================] - 3s 974us/step - loss: 0.1199 - val_loss: 0.1316\n",
      "Epoch 112/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1181 - val_loss: 0.1300\n",
      "Epoch 113/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1166 - val_loss: 0.1284\n",
      "Epoch 114/250\n",
      "3125/3125 [==============================] - 3s 887us/step - loss: 0.1149 - val_loss: 0.1268\n",
      "Epoch 115/250\n",
      "3125/3125 [==============================] - 3s 860us/step - loss: 0.1132 - val_loss: 0.1252\n",
      "Epoch 116/250\n",
      "3125/3125 [==============================] - 3s 869us/step - loss: 0.1116 - val_loss: 0.1237\n",
      "Epoch 117/250\n",
      "3125/3125 [==============================] - 3s 864us/step - loss: 0.1101 - val_loss: 0.1222\n",
      "Epoch 118/250\n",
      "3125/3125 [==============================] - 3s 856us/step - loss: 0.1083 - val_loss: 0.1207\n",
      "Epoch 119/250\n",
      "3125/3125 [==============================] - 3s 887us/step - loss: 0.1065 - val_loss: 0.1192\n",
      "Epoch 120/250\n",
      "3125/3125 [==============================] - 3s 913us/step - loss: 0.1052 - val_loss: 0.1177\n",
      "Epoch 121/250\n",
      "3125/3125 [==============================] - 3s 889us/step - loss: 0.1035 - val_loss: 0.1162\n",
      "Epoch 122/250\n",
      "3125/3125 [==============================] - 3s 972us/step - loss: 0.1020 - val_loss: 0.1148\n",
      "Epoch 123/250\n",
      "3125/3125 [==============================] - 3s 890us/step - loss: 0.1003 - val_loss: 0.1134\n",
      "Epoch 124/250\n",
      "3125/3125 [==============================] - 3s 870us/step - loss: 0.0986 - val_loss: 0.1120\n",
      "Epoch 125/250\n",
      "3125/3125 [==============================] - 3s 881us/step - loss: 0.0973 - val_loss: 0.1106\n",
      "Epoch 126/250\n",
      "3125/3125 [==============================] - 3s 880us/step - loss: 0.0957 - val_loss: 0.1092\n",
      "Epoch 127/250\n",
      "3125/3125 [==============================] - 3s 865us/step - loss: 0.0944 - val_loss: 0.1079\n",
      "Epoch 128/250\n",
      "3125/3125 [==============================] - 3s 859us/step - loss: 0.0930 - val_loss: 0.1065\n",
      "Epoch 129/250\n",
      "3125/3125 [==============================] - 3s 876us/step - loss: 0.0917 - val_loss: 0.1052\n",
      "Epoch 130/250\n",
      "3125/3125 [==============================] - 3s 878us/step - loss: 0.0901 - val_loss: 0.1039\n",
      "Epoch 131/250\n",
      "3125/3125 [==============================] - 3s 872us/step - loss: 0.0888 - val_loss: 0.1026\n",
      "Epoch 132/250\n",
      "3125/3125 [==============================] - 3s 885us/step - loss: 0.0874 - val_loss: 0.1014\n",
      "Epoch 133/250\n",
      "3125/3125 [==============================] - 3s 848us/step - loss: 0.0861 - val_loss: 0.1001\n",
      "Epoch 134/250\n",
      "3125/3125 [==============================] - 3s 860us/step - loss: 0.0846 - val_loss: 0.0989\n",
      "Epoch 135/250\n",
      "3125/3125 [==============================] - 3s 852us/step - loss: 0.0832 - val_loss: 0.0977\n",
      "Epoch 136/250\n",
      "3125/3125 [==============================] - 3s 866us/step - loss: 0.0821 - val_loss: 0.0965\n",
      "Epoch 137/250\n",
      "3125/3125 [==============================] - 3s 860us/step - loss: 0.0810 - val_loss: 0.0954\n",
      "Epoch 138/250\n",
      "3125/3125 [==============================] - 3s 855us/step - loss: 0.0794 - val_loss: 0.0942\n",
      "Epoch 139/250\n",
      "3125/3125 [==============================] - 3s 857us/step - loss: 0.0785 - val_loss: 0.0931\n",
      "Epoch 140/250\n",
      "3125/3125 [==============================] - 3s 874us/step - loss: 0.0771 - val_loss: 0.0920\n",
      "Epoch 141/250\n",
      "3125/3125 [==============================] - 3s 854us/step - loss: 0.0761 - val_loss: 0.0909\n",
      "Epoch 142/250\n",
      "3125/3125 [==============================] - 3s 844us/step - loss: 0.0748 - val_loss: 0.0898\n",
      "Epoch 143/250\n",
      "3125/3125 [==============================] - 3s 915us/step - loss: 0.0736 - val_loss: 0.0888\n",
      "Epoch 144/250\n",
      "3125/3125 [==============================] - 3s 859us/step - loss: 0.0725 - val_loss: 0.0877\n",
      "Epoch 145/250\n",
      "3125/3125 [==============================] - 3s 927us/step - loss: 0.0715 - val_loss: 0.0867\n",
      "Epoch 146/250\n",
      "3125/3125 [==============================] - 3s 874us/step - loss: 0.0701 - val_loss: 0.0857\n",
      "Epoch 147/250\n",
      "3125/3125 [==============================] - 3s 884us/step - loss: 0.0691 - val_loss: 0.0847\n",
      "Epoch 148/250\n",
      "3125/3125 [==============================] - 3s 929us/step - loss: 0.0680 - val_loss: 0.0838\n",
      "Epoch 149/250\n",
      "3125/3125 [==============================] - 3s 881us/step - loss: 0.0674 - val_loss: 0.0828\n",
      "Epoch 150/250\n",
      "3125/3125 [==============================] - 3s 895us/step - loss: 0.0660 - val_loss: 0.0819\n",
      "Epoch 151/250\n",
      "3125/3125 [==============================] - 3s 887us/step - loss: 0.0651 - val_loss: 0.0810\n",
      "Epoch 152/250\n",
      "3125/3125 [==============================] - 3s 893us/step - loss: 0.0643 - val_loss: 0.0801\n",
      "Epoch 153/250\n",
      "3125/3125 [==============================] - 3s 904us/step - loss: 0.0635 - val_loss: 0.0792\n",
      "Epoch 154/250\n",
      "3125/3125 [==============================] - 3s 896us/step - loss: 0.0622 - val_loss: 0.0783\n",
      "Epoch 155/250\n",
      "3125/3125 [==============================] - 3s 896us/step - loss: 0.0614 - val_loss: 0.0775\n",
      "Epoch 156/250\n",
      "3125/3125 [==============================] - 3s 978us/step - loss: 0.0602 - val_loss: 0.0767\n",
      "Epoch 157/250\n",
      "3125/3125 [==============================] - 3s 907us/step - loss: 0.0596 - val_loss: 0.0759\n",
      "Epoch 158/250\n",
      "3125/3125 [==============================] - 3s 887us/step - loss: 0.0586 - val_loss: 0.0751\n",
      "Epoch 159/250\n",
      "3125/3125 [==============================] - 3s 912us/step - loss: 0.0581 - val_loss: 0.0743\n",
      "Epoch 160/250\n",
      "3125/3125 [==============================] - 3s 905us/step - loss: 0.0569 - val_loss: 0.0735\n",
      "Epoch 161/250\n",
      "3125/3125 [==============================] - 3s 892us/step - loss: 0.0561 - val_loss: 0.0728\n",
      "Epoch 162/250\n",
      "3125/3125 [==============================] - 3s 859us/step - loss: 0.0553 - val_loss: 0.0720\n",
      "Epoch 163/250\n",
      "3125/3125 [==============================] - 3s 894us/step - loss: 0.0547 - val_loss: 0.0713\n",
      "Epoch 164/250\n",
      "3125/3125 [==============================] - 3s 897us/step - loss: 0.0537 - val_loss: 0.0706\n",
      "Epoch 165/250\n",
      "3125/3125 [==============================] - 3s 872us/step - loss: 0.0531 - val_loss: 0.0699\n",
      "Epoch 166/250\n",
      "3125/3125 [==============================] - 3s 880us/step - loss: 0.0525 - val_loss: 0.0693\n",
      "Epoch 167/250\n",
      "3125/3125 [==============================] - 3s 946us/step - loss: 0.0518 - val_loss: 0.0686\n",
      "Epoch 168/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0507 - val_loss: 0.0680\n",
      "Epoch 169/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0500 - val_loss: 0.0673\n",
      "Epoch 170/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0496 - val_loss: 0.0667\n",
      "Epoch 171/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0490 - val_loss: 0.0661\n",
      "Epoch 172/250\n",
      "3125/3125 [==============================] - 3s 962us/step - loss: 0.0483 - val_loss: 0.0655\n",
      "Epoch 173/250\n",
      "3125/3125 [==============================] - 3s 998us/step - loss: 0.0477 - val_loss: 0.0650\n",
      "Epoch 174/250\n",
      "3125/3125 [==============================] - 3s 968us/step - loss: 0.0468 - val_loss: 0.0644\n",
      "Epoch 175/250\n",
      "3125/3125 [==============================] - 3s 948us/step - loss: 0.0464 - val_loss: 0.0638\n",
      "Epoch 176/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0458 - val_loss: 0.0633\n",
      "Epoch 177/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0453 - val_loss: 0.0628\n",
      "Epoch 178/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0446 - val_loss: 0.0623\n",
      "Epoch 179/250\n",
      "3125/3125 [==============================] - 3s 998us/step - loss: 0.0443 - val_loss: 0.0618\n",
      "Epoch 180/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0434 - val_loss: 0.0613\n",
      "Epoch 181/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0431 - val_loss: 0.0608\n",
      "Epoch 182/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0424 - val_loss: 0.0603\n",
      "Epoch 183/250\n",
      "3125/3125 [==============================] - 3s 931us/step - loss: 0.0422 - val_loss: 0.0599\n",
      "Epoch 184/250\n",
      "3125/3125 [==============================] - 3s 913us/step - loss: 0.0415 - val_loss: 0.0594\n",
      "Epoch 185/250\n",
      "3125/3125 [==============================] - 3s 892us/step - loss: 0.0410 - val_loss: 0.0590\n",
      "Epoch 186/250\n",
      "3125/3125 [==============================] - 3s 869us/step - loss: 0.0404 - val_loss: 0.0585\n",
      "Epoch 187/250\n",
      "3125/3125 [==============================] - 3s 892us/step - loss: 0.0401 - val_loss: 0.0581\n",
      "Epoch 188/250\n",
      "3125/3125 [==============================] - 3s 905us/step - loss: 0.0393 - val_loss: 0.0577\n",
      "Epoch 189/250\n",
      "3125/3125 [==============================] - 3s 877us/step - loss: 0.0392 - val_loss: 0.0573\n",
      "Epoch 190/250\n",
      "3125/3125 [==============================] - 3s 871us/step - loss: 0.0389 - val_loss: 0.0569\n",
      "Epoch 191/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0383 - val_loss: 0.0566\n",
      "Epoch 192/250\n",
      "3125/3125 [==============================] - 3s 955us/step - loss: 0.0382 - val_loss: 0.0562\n",
      "Epoch 193/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0376 - val_loss: 0.0558\n",
      "Epoch 194/250\n",
      "3125/3125 [==============================] - 3s 905us/step - loss: 0.0371 - val_loss: 0.0555\n",
      "Epoch 195/250\n",
      "3125/3125 [==============================] - 3s 932us/step - loss: 0.0369 - val_loss: 0.0551\n",
      "Epoch 196/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0363 - val_loss: 0.0548\n",
      "Epoch 197/250\n",
      "3125/3125 [==============================] - 3s 882us/step - loss: 0.0355 - val_loss: 0.0545\n",
      "Epoch 198/250\n",
      "3125/3125 [==============================] - 3s 875us/step - loss: 0.0353 - val_loss: 0.0541\n",
      "Epoch 199/250\n",
      "3125/3125 [==============================] - 3s 872us/step - loss: 0.0354 - val_loss: 0.0538\n",
      "Epoch 200/250\n",
      "3125/3125 [==============================] - 3s 964us/step - loss: 0.0349 - val_loss: 0.0535\n",
      "Epoch 201/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0348 - val_loss: 0.0532\n",
      "Epoch 202/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0341 - val_loss: 0.0529\n",
      "Epoch 203/250\n",
      "3125/3125 [==============================] - 3s 990us/step - loss: 0.0339 - val_loss: 0.0526\n",
      "Epoch 204/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0337 - val_loss: 0.0524\n",
      "Epoch 205/250\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0333 - val_loss: 0.0521\n",
      "Epoch 206/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0332 - val_loss: 0.0518\n",
      "Epoch 207/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0326 - val_loss: 0.0516\n",
      "Epoch 208/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0323 - val_loss: 0.0513\n",
      "Epoch 209/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0322 - val_loss: 0.0511\n",
      "Epoch 210/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0319 - val_loss: 0.0508\n",
      "Epoch 211/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0316 - val_loss: 0.0506\n",
      "Epoch 212/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0312 - val_loss: 0.0504\n",
      "Epoch 213/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0309 - val_loss: 0.0502\n",
      "Epoch 214/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0308 - val_loss: 0.0499\n",
      "Epoch 215/250\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.0303 - val_loss: 0.0497\n",
      "Epoch 216/250\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.0301 - val_loss: 0.0495\n",
      "Epoch 217/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0303 - val_loss: 0.0493\n",
      "Epoch 218/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0297 - val_loss: 0.0491\n",
      "Epoch 219/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0295 - val_loss: 0.0489\n",
      "Epoch 220/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0294 - val_loss: 0.0487\n",
      "Epoch 221/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0291 - val_loss: 0.0486\n",
      "Epoch 222/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0292 - val_loss: 0.0484\n",
      "Epoch 223/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0289 - val_loss: 0.0482\n",
      "Epoch 224/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0285 - val_loss: 0.0480\n",
      "Epoch 225/250\n",
      "3125/3125 [==============================] - 3s 901us/step - loss: 0.0285 - val_loss: 0.0479\n",
      "Epoch 226/250\n",
      "3125/3125 [==============================] - 3s 992us/step - loss: 0.0283 - val_loss: 0.0477\n",
      "Epoch 227/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0282 - val_loss: 0.0475\n",
      "Epoch 228/250\n",
      "3125/3125 [==============================] - 3s 940us/step - loss: 0.0282 - val_loss: 0.0474\n",
      "Epoch 229/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0276 - val_loss: 0.0472\n",
      "Epoch 230/250\n",
      "3125/3125 [==============================] - 3s 918us/step - loss: 0.0274 - val_loss: 0.0471\n",
      "Epoch 231/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0272 - val_loss: 0.0469\n",
      "Epoch 232/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0271 - val_loss: 0.0468\n",
      "Epoch 233/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0268 - val_loss: 0.0467\n",
      "Epoch 234/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0269 - val_loss: 0.0465\n",
      "Epoch 235/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0265 - val_loss: 0.0464\n",
      "Epoch 236/250\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0267 - val_loss: 0.0463\n",
      "Epoch 237/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0262 - val_loss: 0.0462\n",
      "Epoch 238/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0262 - val_loss: 0.0460\n",
      "Epoch 239/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0260 - val_loss: 0.0459\n",
      "Epoch 240/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0259 - val_loss: 0.0458\n",
      "Epoch 241/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0260 - val_loss: 0.0457\n",
      "Epoch 242/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0256 - val_loss: 0.0456\n",
      "Epoch 243/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0257 - val_loss: 0.0455\n",
      "Epoch 244/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0253 - val_loss: 0.0454\n",
      "Epoch 245/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0251 - val_loss: 0.0453\n",
      "Epoch 246/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0252 - val_loss: 0.0451\n",
      "Epoch 247/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0251 - val_loss: 0.0451\n",
      "Epoch 248/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0250 - val_loss: 0.0450\n",
      "Epoch 249/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0251 - val_loss: 0.0449\n",
      "Epoch 250/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0245 - val_loss: 0.0448\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# Sparse - AE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pretrain_features_size = 10\n",
    "target_dim_size = 32\n",
    "autoencoder = Autoencoder()\n",
    "autoencoder.build_sparse_ae(pretrain_features_size, target_dim_size)\n",
    "\n",
    "history = autoencoder.train(features, features, features_test, features_test,\n",
    "                 epochs=250,\n",
    "                 batch_size=16,\n",
    "                 shuffle=True)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Sparse Autoencoder')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "autoencoder.save('model-ae/sparse-ae-decoder.h5', 'model-ae/sparse-ae-encoder.h5')\n",
    "print (\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.6540 - val_loss: 0.6451\n",
      "Epoch 2/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.6408 - val_loss: 0.6311\n",
      "Epoch 3/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.6267 - val_loss: 0.6165\n",
      "Epoch 4/250\n",
      "3125/3125 [==============================] - 3s 995us/step - loss: 0.6115 - val_loss: 0.6016\n",
      "Epoch 5/250\n",
      "3125/3125 [==============================] - 3s 872us/step - loss: 0.5965 - val_loss: 0.5867\n",
      "Epoch 6/250\n",
      "3125/3125 [==============================] - 3s 849us/step - loss: 0.5817 - val_loss: 0.5718\n",
      "Epoch 7/250\n",
      "3125/3125 [==============================] - 3s 834us/step - loss: 0.5664 - val_loss: 0.5566\n",
      "Epoch 8/250\n",
      "3125/3125 [==============================] - 3s 892us/step - loss: 0.5509 - val_loss: 0.5410\n",
      "Epoch 9/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.5351 - val_loss: 0.5253\n",
      "Epoch 10/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.5198 - val_loss: 0.5095\n",
      "Epoch 11/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.5037 - val_loss: 0.4937\n",
      "Epoch 12/250\n",
      "3125/3125 [==============================] - 3s 932us/step - loss: 0.4880 - val_loss: 0.4782\n",
      "Epoch 13/250\n",
      "3125/3125 [==============================] - 3s 884us/step - loss: 0.4725 - val_loss: 0.4630\n",
      "Epoch 14/250\n",
      "3125/3125 [==============================] - 3s 885us/step - loss: 0.4574 - val_loss: 0.4480\n",
      "Epoch 15/250\n",
      "3125/3125 [==============================] - 3s 898us/step - loss: 0.4430 - val_loss: 0.4335\n",
      "Epoch 16/250\n",
      "3125/3125 [==============================] - 3s 868us/step - loss: 0.4280 - val_loss: 0.4194\n",
      "Epoch 17/250\n",
      "3125/3125 [==============================] - 3s 868us/step - loss: 0.4144 - val_loss: 0.4059\n",
      "Epoch 18/250\n",
      "3125/3125 [==============================] - 3s 842us/step - loss: 0.4010 - val_loss: 0.3930\n",
      "Epoch 19/250\n",
      "3125/3125 [==============================] - 3s 854us/step - loss: 0.3882 - val_loss: 0.3805\n",
      "Epoch 20/250\n",
      "3125/3125 [==============================] - 3s 876us/step - loss: 0.3762 - val_loss: 0.3688\n",
      "Epoch 21/250\n",
      "3125/3125 [==============================] - 3s 861us/step - loss: 0.3645 - val_loss: 0.3578\n",
      "Epoch 22/250\n",
      "3125/3125 [==============================] - 3s 947us/step - loss: 0.3538 - val_loss: 0.3475\n",
      "Epoch 23/250\n",
      "3125/3125 [==============================] - 3s 857us/step - loss: 0.3435 - val_loss: 0.3378\n",
      "Epoch 24/250\n",
      "3125/3125 [==============================] - 3s 908us/step - loss: 0.3344 - val_loss: 0.3287\n",
      "Epoch 25/250\n",
      "3125/3125 [==============================] - 3s 895us/step - loss: 0.3250 - val_loss: 0.3201\n",
      "Epoch 26/250\n",
      "3125/3125 [==============================] - 3s 995us/step - loss: 0.3167 - val_loss: 0.3124\n",
      "Epoch 27/250\n",
      "3125/3125 [==============================] - 3s 841us/step - loss: 0.3090 - val_loss: 0.3053\n",
      "Epoch 28/250\n",
      "3125/3125 [==============================] - 3s 833us/step - loss: 0.3020 - val_loss: 0.2988\n",
      "Epoch 29/250\n",
      "3125/3125 [==============================] - 3s 959us/step - loss: 0.2955 - val_loss: 0.2931\n",
      "Epoch 30/250\n",
      "3125/3125 [==============================] - 3s 972us/step - loss: 0.2897 - val_loss: 0.2879\n",
      "Epoch 31/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.2848 - val_loss: 0.2832\n",
      "Epoch 32/250\n",
      "3125/3125 [==============================] - 3s 989us/step - loss: 0.2798 - val_loss: 0.2789\n",
      "Epoch 33/250\n",
      "3125/3125 [==============================] - 3s 849us/step - loss: 0.2753 - val_loss: 0.2750\n",
      "Epoch 34/250\n",
      "3125/3125 [==============================] - 3s 876us/step - loss: 0.2716 - val_loss: 0.2714\n",
      "Epoch 35/250\n",
      "3125/3125 [==============================] - 3s 896us/step - loss: 0.2679 - val_loss: 0.2680\n",
      "Epoch 36/250\n",
      "3125/3125 [==============================] - 3s 856us/step - loss: 0.2642 - val_loss: 0.2648\n",
      "Epoch 37/250\n",
      "3125/3125 [==============================] - 3s 906us/step - loss: 0.2613 - val_loss: 0.2617\n",
      "Epoch 38/250\n",
      "3125/3125 [==============================] - 3s 936us/step - loss: 0.2582 - val_loss: 0.2588\n",
      "Epoch 39/250\n",
      "3125/3125 [==============================] - 3s 957us/step - loss: 0.2553 - val_loss: 0.2560\n",
      "Epoch 40/250\n",
      "3125/3125 [==============================] - 3s 842us/step - loss: 0.2523 - val_loss: 0.2533\n",
      "Epoch 41/250\n",
      "3125/3125 [==============================] - 3s 855us/step - loss: 0.2488 - val_loss: 0.2507\n",
      "Epoch 42/250\n",
      "3125/3125 [==============================] - 3s 844us/step - loss: 0.2465 - val_loss: 0.2481\n",
      "Epoch 43/250\n",
      "3125/3125 [==============================] - 3s 842us/step - loss: 0.2437 - val_loss: 0.2456\n",
      "Epoch 44/250\n",
      "3125/3125 [==============================] - 3s 859us/step - loss: 0.2412 - val_loss: 0.2431\n",
      "Epoch 45/250\n",
      "3125/3125 [==============================] - 3s 919us/step - loss: 0.2386 - val_loss: 0.2407\n",
      "Epoch 46/250\n",
      "3125/3125 [==============================] - 3s 854us/step - loss: 0.2359 - val_loss: 0.2383\n",
      "Epoch 47/250\n",
      "3125/3125 [==============================] - 3s 861us/step - loss: 0.2333 - val_loss: 0.2360\n",
      "Epoch 48/250\n",
      "3125/3125 [==============================] - 3s 850us/step - loss: 0.2309 - val_loss: 0.2337\n",
      "Epoch 49/250\n",
      "3125/3125 [==============================] - 3s 865us/step - loss: 0.2284 - val_loss: 0.2314\n",
      "Epoch 50/250\n",
      "3125/3125 [==============================] - 3s 846us/step - loss: 0.2261 - val_loss: 0.2291\n",
      "Epoch 51/250\n",
      "3125/3125 [==============================] - 3s 844us/step - loss: 0.2235 - val_loss: 0.2268\n",
      "Epoch 52/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.2210 - val_loss: 0.2245\n",
      "Epoch 53/250\n",
      "3125/3125 [==============================] - 3s 838us/step - loss: 0.2187 - val_loss: 0.2223\n",
      "Epoch 54/250\n",
      "3125/3125 [==============================] - 3s 849us/step - loss: 0.2162 - val_loss: 0.2200\n",
      "Epoch 55/250\n",
      "3125/3125 [==============================] - 3s 845us/step - loss: 0.2139 - val_loss: 0.2178\n",
      "Epoch 56/250\n",
      "3125/3125 [==============================] - 3s 858us/step - loss: 0.2118 - val_loss: 0.2155\n",
      "Epoch 57/250\n",
      "3125/3125 [==============================] - 3s 851us/step - loss: 0.2090 - val_loss: 0.2133\n",
      "Epoch 58/250\n",
      "3125/3125 [==============================] - 3s 847us/step - loss: 0.2069 - val_loss: 0.2110\n",
      "Epoch 59/250\n",
      "3125/3125 [==============================] - 3s 913us/step - loss: 0.2045 - val_loss: 0.2088\n",
      "Epoch 60/250\n",
      "3125/3125 [==============================] - 3s 860us/step - loss: 0.2019 - val_loss: 0.2066\n",
      "Epoch 61/250\n",
      "3125/3125 [==============================] - 3s 846us/step - loss: 0.1996 - val_loss: 0.2044\n",
      "Epoch 62/250\n",
      "3125/3125 [==============================] - 3s 825us/step - loss: 0.1973 - val_loss: 0.2021\n",
      "Epoch 63/250\n",
      "3125/3125 [==============================] - 3s 840us/step - loss: 0.1952 - val_loss: 0.2000\n",
      "Epoch 64/250\n",
      "3125/3125 [==============================] - 3s 842us/step - loss: 0.1927 - val_loss: 0.1978\n",
      "Epoch 65/250\n",
      "3125/3125 [==============================] - 3s 836us/step - loss: 0.1902 - val_loss: 0.1956\n",
      "Epoch 66/250\n",
      "3125/3125 [==============================] - 3s 845us/step - loss: 0.1883 - val_loss: 0.1934\n",
      "Epoch 67/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1858 - val_loss: 0.1912\n",
      "Epoch 68/250\n",
      "3125/3125 [==============================] - 3s 867us/step - loss: 0.1833 - val_loss: 0.1891\n",
      "Epoch 69/250\n",
      "3125/3125 [==============================] - 3s 845us/step - loss: 0.1809 - val_loss: 0.1869\n",
      "Epoch 70/250\n",
      "3125/3125 [==============================] - 3s 831us/step - loss: 0.1789 - val_loss: 0.1848\n",
      "Epoch 71/250\n",
      "3125/3125 [==============================] - 3s 855us/step - loss: 0.1765 - val_loss: 0.1826\n",
      "Epoch 72/250\n",
      "3125/3125 [==============================] - 3s 870us/step - loss: 0.1741 - val_loss: 0.1805\n",
      "Epoch 73/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1718 - val_loss: 0.1784\n",
      "Epoch 74/250\n",
      "3125/3125 [==============================] - 3s 914us/step - loss: 0.1695 - val_loss: 0.1763\n",
      "Epoch 75/250\n",
      "3125/3125 [==============================] - 3s 835us/step - loss: 0.1677 - val_loss: 0.1742\n",
      "Epoch 76/250\n",
      "3125/3125 [==============================] - 3s 846us/step - loss: 0.1651 - val_loss: 0.1721\n",
      "Epoch 77/250\n",
      "3125/3125 [==============================] - 3s 846us/step - loss: 0.1632 - val_loss: 0.1700\n",
      "Epoch 78/250\n",
      "3125/3125 [==============================] - 3s 855us/step - loss: 0.1610 - val_loss: 0.1680\n",
      "Epoch 79/250\n",
      "3125/3125 [==============================] - 3s 840us/step - loss: 0.1587 - val_loss: 0.1660\n",
      "Epoch 80/250\n",
      "3125/3125 [==============================] - 3s 845us/step - loss: 0.1567 - val_loss: 0.1639\n",
      "Epoch 81/250\n",
      "3125/3125 [==============================] - 3s 954us/step - loss: 0.1545 - val_loss: 0.1619\n",
      "Epoch 82/250\n",
      "3125/3125 [==============================] - 3s 872us/step - loss: 0.1521 - val_loss: 0.1600\n",
      "Epoch 83/250\n",
      "3125/3125 [==============================] - 3s 853us/step - loss: 0.1502 - val_loss: 0.1580\n",
      "Epoch 84/250\n",
      "3125/3125 [==============================] - 3s 837us/step - loss: 0.1480 - val_loss: 0.1561\n",
      "Epoch 85/250\n",
      "3125/3125 [==============================] - 3s 851us/step - loss: 0.1461 - val_loss: 0.1541\n",
      "Epoch 86/250\n",
      "3125/3125 [==============================] - 3s 842us/step - loss: 0.1440 - val_loss: 0.1523\n",
      "Epoch 87/250\n",
      "3125/3125 [==============================] - 3s 851us/step - loss: 0.1419 - val_loss: 0.1504\n",
      "Epoch 88/250\n",
      "3125/3125 [==============================] - 3s 882us/step - loss: 0.1400 - val_loss: 0.1485\n",
      "Epoch 89/250\n",
      "3125/3125 [==============================] - 3s 932us/step - loss: 0.1379 - val_loss: 0.1467\n",
      "Epoch 90/250\n",
      "3125/3125 [==============================] - 3s 845us/step - loss: 0.1359 - val_loss: 0.1449\n",
      "Epoch 91/250\n",
      "3125/3125 [==============================] - 3s 858us/step - loss: 0.1338 - val_loss: 0.1431\n",
      "Epoch 92/250\n",
      "3125/3125 [==============================] - 3s 853us/step - loss: 0.1321 - val_loss: 0.1413\n",
      "Epoch 93/250\n",
      "3125/3125 [==============================] - 3s 848us/step - loss: 0.1298 - val_loss: 0.1395\n",
      "Epoch 94/250\n",
      "3125/3125 [==============================] - 3s 841us/step - loss: 0.1283 - val_loss: 0.1377\n",
      "Epoch 95/250\n",
      "3125/3125 [==============================] - 3s 846us/step - loss: 0.1267 - val_loss: 0.1360\n",
      "Epoch 96/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1245 - val_loss: 0.1343\n",
      "Epoch 97/250\n",
      "3125/3125 [==============================] - 3s 872us/step - loss: 0.1227 - val_loss: 0.1326\n",
      "Epoch 98/250\n",
      "3125/3125 [==============================] - 3s 856us/step - loss: 0.1205 - val_loss: 0.1309\n",
      "Epoch 99/250\n",
      "3125/3125 [==============================] - 3s 862us/step - loss: 0.1192 - val_loss: 0.1293\n",
      "Epoch 100/250\n",
      "3125/3125 [==============================] - 3s 846us/step - loss: 0.1173 - val_loss: 0.1276\n",
      "Epoch 101/250\n",
      "3125/3125 [==============================] - 3s 849us/step - loss: 0.1154 - val_loss: 0.1260\n",
      "Epoch 102/250\n",
      "3125/3125 [==============================] - 3s 913us/step - loss: 0.1138 - val_loss: 0.1244\n",
      "Epoch 103/250\n",
      "3125/3125 [==============================] - 3s 903us/step - loss: 0.1122 - val_loss: 0.1228\n",
      "Epoch 104/250\n",
      "3125/3125 [==============================] - 3s 868us/step - loss: 0.1102 - val_loss: 0.1212\n",
      "Epoch 105/250\n",
      "3125/3125 [==============================] - 3s 881us/step - loss: 0.1085 - val_loss: 0.1197\n",
      "Epoch 106/250\n",
      "3125/3125 [==============================] - 3s 903us/step - loss: 0.1068 - val_loss: 0.1182\n",
      "Epoch 107/250\n",
      "3125/3125 [==============================] - 3s 841us/step - loss: 0.1054 - val_loss: 0.1167\n",
      "Epoch 108/250\n",
      "3125/3125 [==============================] - 3s 849us/step - loss: 0.1036 - val_loss: 0.1152\n",
      "Epoch 109/250\n",
      "3125/3125 [==============================] - 3s 863us/step - loss: 0.1022 - val_loss: 0.1137\n",
      "Epoch 110/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.1004 - val_loss: 0.1123\n",
      "Epoch 111/250\n",
      "3125/3125 [==============================] - 3s 900us/step - loss: 0.0987 - val_loss: 0.1108\n",
      "Epoch 112/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0975 - val_loss: 0.1094\n",
      "Epoch 113/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0962 - val_loss: 0.1080\n",
      "Epoch 114/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0946 - val_loss: 0.1066\n",
      "Epoch 115/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0931 - val_loss: 0.1052\n",
      "Epoch 116/250\n",
      "3125/3125 [==============================] - 3s 982us/step - loss: 0.0913 - val_loss: 0.1039\n",
      "Epoch 117/250\n",
      "3125/3125 [==============================] - 3s 948us/step - loss: 0.0900 - val_loss: 0.1026\n",
      "Epoch 118/250\n",
      "3125/3125 [==============================] - 3s 923us/step - loss: 0.0885 - val_loss: 0.1013\n",
      "Epoch 119/250\n",
      "3125/3125 [==============================] - 3s 895us/step - loss: 0.0874 - val_loss: 0.1000\n",
      "Epoch 120/250\n",
      "3125/3125 [==============================] - 3s 837us/step - loss: 0.0857 - val_loss: 0.0987\n",
      "Epoch 121/250\n",
      "3125/3125 [==============================] - 3s 853us/step - loss: 0.0844 - val_loss: 0.0975\n",
      "Epoch 122/250\n",
      "3125/3125 [==============================] - 3s 843us/step - loss: 0.0831 - val_loss: 0.0963\n",
      "Epoch 123/250\n",
      "3125/3125 [==============================] - 3s 847us/step - loss: 0.0821 - val_loss: 0.0951\n",
      "Epoch 124/250\n",
      "3125/3125 [==============================] - 3s 870us/step - loss: 0.0805 - val_loss: 0.0939\n",
      "Epoch 125/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0791 - val_loss: 0.0927\n",
      "Epoch 126/250\n",
      "3125/3125 [==============================] - 3s 905us/step - loss: 0.0779 - val_loss: 0.0916\n",
      "Epoch 127/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0767 - val_loss: 0.0904\n",
      "Epoch 128/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0756 - val_loss: 0.0893\n",
      "Epoch 129/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0741 - val_loss: 0.0883\n",
      "Epoch 130/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0732 - val_loss: 0.0872\n",
      "Epoch 131/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0721 - val_loss: 0.0861\n",
      "Epoch 132/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0708 - val_loss: 0.0851\n",
      "Epoch 133/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0698 - val_loss: 0.0841\n",
      "Epoch 134/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0687 - val_loss: 0.0831\n",
      "Epoch 135/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0677 - val_loss: 0.0821\n",
      "Epoch 136/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0666 - val_loss: 0.0812\n",
      "Epoch 137/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0655 - val_loss: 0.0802\n",
      "Epoch 138/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0647 - val_loss: 0.0793\n",
      "Epoch 139/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0633 - val_loss: 0.0784\n",
      "Epoch 140/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0623 - val_loss: 0.0775\n",
      "Epoch 141/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0618 - val_loss: 0.0766\n",
      "Epoch 142/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0608 - val_loss: 0.0758\n",
      "Epoch 143/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0595 - val_loss: 0.0749\n",
      "Epoch 144/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0586 - val_loss: 0.0741\n",
      "Epoch 145/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0580 - val_loss: 0.0733\n",
      "Epoch 146/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0569 - val_loss: 0.0725\n",
      "Epoch 147/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0563 - val_loss: 0.0717\n",
      "Epoch 148/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0553 - val_loss: 0.0710\n",
      "Epoch 149/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0542 - val_loss: 0.0702\n",
      "Epoch 150/250\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.0537 - val_loss: 0.0695\n",
      "Epoch 151/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0528 - val_loss: 0.0688\n",
      "Epoch 152/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0520 - val_loss: 0.0680\n",
      "Epoch 153/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0512 - val_loss: 0.0674\n",
      "Epoch 154/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0505 - val_loss: 0.0667\n",
      "Epoch 155/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0496 - val_loss: 0.0660\n",
      "Epoch 156/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0491 - val_loss: 0.0654\n",
      "Epoch 157/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0484 - val_loss: 0.0647\n",
      "Epoch 158/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0477 - val_loss: 0.0641\n",
      "Epoch 159/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0471 - val_loss: 0.0635\n",
      "Epoch 160/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0461 - val_loss: 0.0629\n",
      "Epoch 161/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0454 - val_loss: 0.0623\n",
      "Epoch 162/250\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0451 - val_loss: 0.0617\n",
      "Epoch 163/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0444 - val_loss: 0.0612\n",
      "Epoch 164/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0438 - val_loss: 0.0606\n",
      "Epoch 165/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0434 - val_loss: 0.0601\n",
      "Epoch 166/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0427 - val_loss: 0.0596\n",
      "Epoch 167/250\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0421 - val_loss: 0.0591\n",
      "Epoch 168/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0415 - val_loss: 0.0586\n",
      "Epoch 169/250\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0410 - val_loss: 0.0581\n",
      "Epoch 170/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0404 - val_loss: 0.0576\n",
      "Epoch 171/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0399 - val_loss: 0.0572\n",
      "Epoch 172/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0392 - val_loss: 0.0567\n",
      "Epoch 173/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0388 - val_loss: 0.0563\n",
      "Epoch 174/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0386 - val_loss: 0.0558\n",
      "Epoch 175/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0376 - val_loss: 0.0554\n",
      "Epoch 176/250\n",
      "3125/3125 [==============================] - 3s 981us/step - loss: 0.0374 - val_loss: 0.0550\n",
      "Epoch 177/250\n",
      "3125/3125 [==============================] - 3s 974us/step - loss: 0.0369 - val_loss: 0.0546\n",
      "Epoch 178/250\n",
      "3125/3125 [==============================] - 3s 958us/step - loss: 0.0366 - val_loss: 0.0542\n",
      "Epoch 179/250\n",
      "3125/3125 [==============================] - 3s 956us/step - loss: 0.0360 - val_loss: 0.0538\n",
      "Epoch 180/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0358 - val_loss: 0.0534\n",
      "Epoch 181/250\n",
      "3125/3125 [==============================] - 3s 972us/step - loss: 0.0352 - val_loss: 0.0531\n",
      "Epoch 182/250\n",
      "3125/3125 [==============================] - 3s 940us/step - loss: 0.0348 - val_loss: 0.0527\n",
      "Epoch 183/250\n",
      "3125/3125 [==============================] - 3s 925us/step - loss: 0.0342 - val_loss: 0.0523\n",
      "Epoch 184/250\n",
      "3125/3125 [==============================] - 3s 918us/step - loss: 0.0341 - val_loss: 0.0520\n",
      "Epoch 185/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0336 - val_loss: 0.0517\n",
      "Epoch 186/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0335 - val_loss: 0.0513\n",
      "Epoch 187/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0329 - val_loss: 0.0510\n",
      "Epoch 188/250\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0325 - val_loss: 0.0507\n",
      "Epoch 189/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0322 - val_loss: 0.0504\n",
      "Epoch 190/250\n",
      "3125/3125 [==============================] - 3s 994us/step - loss: 0.0320 - val_loss: 0.0501\n",
      "Epoch 191/250\n",
      "3125/3125 [==============================] - 3s 985us/step - loss: 0.0317 - val_loss: 0.0498\n",
      "Epoch 192/250\n",
      "3125/3125 [==============================] - 3s 967us/step - loss: 0.0313 - val_loss: 0.0495\n",
      "Epoch 193/250\n",
      "3125/3125 [==============================] - 3s 972us/step - loss: 0.0308 - val_loss: 0.0493\n",
      "Epoch 194/250\n",
      "3125/3125 [==============================] - 3s 994us/step - loss: 0.0307 - val_loss: 0.0490\n",
      "Epoch 195/250\n",
      "3125/3125 [==============================] - 3s 968us/step - loss: 0.0304 - val_loss: 0.0487\n",
      "Epoch 196/250\n",
      "3125/3125 [==============================] - 3s 982us/step - loss: 0.0299 - val_loss: 0.0485\n",
      "Epoch 197/250\n",
      "3125/3125 [==============================] - 3s 967us/step - loss: 0.0298 - val_loss: 0.0482\n",
      "Epoch 198/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0297 - val_loss: 0.0480\n",
      "Epoch 199/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0292 - val_loss: 0.0478\n",
      "Epoch 200/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0290 - val_loss: 0.0475\n",
      "Epoch 201/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0288 - val_loss: 0.0473\n",
      "Epoch 202/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0285 - val_loss: 0.0471\n",
      "Epoch 203/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0281 - val_loss: 0.0469\n",
      "Epoch 204/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0281 - val_loss: 0.0467\n",
      "Epoch 205/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0276 - val_loss: 0.0465\n",
      "Epoch 206/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0276 - val_loss: 0.0463\n",
      "Epoch 207/250\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0273 - val_loss: 0.0461\n",
      "Epoch 208/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0270 - val_loss: 0.0459\n",
      "Epoch 209/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0269 - val_loss: 0.0457\n",
      "Epoch 210/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0268 - val_loss: 0.0455\n",
      "Epoch 211/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0265 - val_loss: 0.0453\n",
      "Epoch 212/250\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0265 - val_loss: 0.0452\n",
      "Epoch 213/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0258 - val_loss: 0.0450\n",
      "Epoch 214/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0258 - val_loss: 0.0448\n",
      "Epoch 215/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0255 - val_loss: 0.0447\n",
      "Epoch 216/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0253 - val_loss: 0.0445\n",
      "Epoch 217/250\n",
      "3125/3125 [==============================] - 3s 984us/step - loss: 0.0251 - val_loss: 0.0444\n",
      "Epoch 218/250\n",
      "3125/3125 [==============================] - 3s 859us/step - loss: 0.0250 - val_loss: 0.0442\n",
      "Epoch 219/250\n",
      "3125/3125 [==============================] - 3s 857us/step - loss: 0.0249 - val_loss: 0.0441\n",
      "Epoch 220/250\n",
      "3125/3125 [==============================] - 3s 863us/step - loss: 0.0248 - val_loss: 0.0439\n",
      "Epoch 221/250\n",
      "3125/3125 [==============================] - 3s 876us/step - loss: 0.0247 - val_loss: 0.0438\n",
      "Epoch 222/250\n",
      "3125/3125 [==============================] - 3s 858us/step - loss: 0.0245 - val_loss: 0.0437\n",
      "Epoch 223/250\n",
      "3125/3125 [==============================] - 3s 861us/step - loss: 0.0244 - val_loss: 0.0435\n",
      "Epoch 224/250\n",
      "3125/3125 [==============================] - 3s 856us/step - loss: 0.0242 - val_loss: 0.0434\n",
      "Epoch 225/250\n",
      "3125/3125 [==============================] - 3s 836us/step - loss: 0.0244 - val_loss: 0.0433\n",
      "Epoch 226/250\n",
      "3125/3125 [==============================] - 3s 844us/step - loss: 0.0240 - val_loss: 0.0432\n",
      "Epoch 227/250\n",
      "3125/3125 [==============================] - 3s 833us/step - loss: 0.0238 - val_loss: 0.0430\n",
      "Epoch 228/250\n",
      "3125/3125 [==============================] - 3s 851us/step - loss: 0.0233 - val_loss: 0.0429\n",
      "Epoch 229/250\n",
      "3125/3125 [==============================] - 3s 983us/step - loss: 0.0235 - val_loss: 0.0428\n",
      "Epoch 230/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0231 - val_loss: 0.0427\n",
      "Epoch 231/250\n",
      "3125/3125 [==============================] - 3s 955us/step - loss: 0.0231 - val_loss: 0.0426\n",
      "Epoch 232/250\n",
      "3125/3125 [==============================] - 3s 847us/step - loss: 0.0231 - val_loss: 0.0425\n",
      "Epoch 233/250\n",
      "3125/3125 [==============================] - 3s 1ms/step - loss: 0.0230 - val_loss: 0.0424\n",
      "Epoch 234/250\n",
      "3125/3125 [==============================] - 3s 841us/step - loss: 0.0226 - val_loss: 0.0423\n",
      "Epoch 235/250\n",
      "3125/3125 [==============================] - 3s 924us/step - loss: 0.0228 - val_loss: 0.0422\n",
      "Epoch 236/250\n",
      "3125/3125 [==============================] - 3s 840us/step - loss: 0.0224 - val_loss: 0.0421\n",
      "Epoch 237/250\n",
      "3125/3125 [==============================] - 3s 863us/step - loss: 0.0224 - val_loss: 0.0420\n",
      "Epoch 238/250\n",
      "3125/3125 [==============================] - 3s 923us/step - loss: 0.0220 - val_loss: 0.0419\n",
      "Epoch 239/250\n",
      "3125/3125 [==============================] - 3s 883us/step - loss: 0.0221 - val_loss: 0.0418\n",
      "Epoch 240/250\n",
      "3125/3125 [==============================] - 3s 829us/step - loss: 0.0223 - val_loss: 0.0417\n",
      "Epoch 241/250\n",
      "3125/3125 [==============================] - 3s 850us/step - loss: 0.0216 - val_loss: 0.0416\n",
      "Epoch 242/250\n",
      "3125/3125 [==============================] - 3s 894us/step - loss: 0.0219 - val_loss: 0.0416\n",
      "Epoch 243/250\n",
      "3125/3125 [==============================] - 3s 836us/step - loss: 0.0220 - val_loss: 0.0415\n",
      "Epoch 244/250\n",
      "3125/3125 [==============================] - 3s 839us/step - loss: 0.0217 - val_loss: 0.0414\n",
      "Epoch 245/250\n",
      "3125/3125 [==============================] - 3s 848us/step - loss: 0.0215 - val_loss: 0.0413\n",
      "Epoch 246/250\n",
      "3125/3125 [==============================] - 3s 870us/step - loss: 0.0215 - val_loss: 0.0412\n",
      "Epoch 247/250\n",
      "3125/3125 [==============================] - 3s 938us/step - loss: 0.0213 - val_loss: 0.0412\n",
      "Epoch 248/250\n",
      "3125/3125 [==============================] - 3s 825us/step - loss: 0.0213 - val_loss: 0.0411\n",
      "Epoch 249/250\n",
      "3125/3125 [==============================] - 3s 834us/step - loss: 0.0211 - val_loss: 0.0410\n",
      "Epoch 250/250\n",
      "3125/3125 [==============================] - 3s 835us/step - loss: 0.0212 - val_loss: 0.0410\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# Simple - AE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pretrain_features_size = 10\n",
    "target_dim_size = 32\n",
    "autoencoder = Autoencoder()\n",
    "autoencoder.build_simple_ae(pretrain_features_size, target_dim_size)\n",
    "\n",
    "history = autoencoder.train(features, features, features_test, features_test,\n",
    "                 epochs=250,\n",
    "                 batch_size=16,\n",
    "                 shuffle=True)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Simple Autoencoder')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "autoencoder.save('model-ae/simple-ae-decoder.h5', 'model-ae/simple-ae-encoder.h5')\n",
    "print (\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.2248 - val_loss: 0.0404\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0155 - val_loss: 0.0378\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0151 - val_loss: 0.0368\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0142 - val_loss: 0.0359\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0140 - val_loss: 0.0347\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0136 - val_loss: 0.0338\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0133 - val_loss: 0.0329\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0127 - val_loss: 0.0321\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0126 - val_loss: 0.0313\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.0125 - val_loss: 0.0310\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.0120 - val_loss: 0.0304\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 5s 1ms/step - loss: 0.0119 - val_loss: 0.0302\n",
      "Epoch 13/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0118 - val_loss: 0.0298\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0118 - val_loss: 0.0296\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0116 - val_loss: 0.0294\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0116 - val_loss: 0.0293\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0114 - val_loss: 0.0291\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0111 - val_loss: 0.0290\n",
      "Epoch 19/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.0113 - val_loss: 0.0289\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0114 - val_loss: 0.0289\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0110 - val_loss: 0.0288\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0110 - val_loss: 0.0287\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0112 - val_loss: 0.0288\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0113 - val_loss: 0.0286\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0113 - val_loss: 0.0286\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0113 - val_loss: 0.0286\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0111 - val_loss: 0.0286\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0285\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0109 - val_loss: 0.0285\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0112 - val_loss: 0.0285\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0109 - val_loss: 0.0285\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 8s 3ms/step - loss: 0.0109 - val_loss: 0.0284\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 8s 3ms/step - loss: 0.0110 - val_loss: 0.0284\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0108 - val_loss: 0.0284\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0108 - val_loss: 0.0284\n",
      "Epoch 36/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0108 - val_loss: 0.0284\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0111 - val_loss: 0.0284\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0109 - val_loss: 0.0283\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0283\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0112 - val_loss: 0.0283\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.0110 - val_loss: 0.0283\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0111 - val_loss: 0.0283\n",
      "Epoch 43/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0283\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0283\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0112 - val_loss: 0.0283\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0283\n",
      "Epoch 47/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0283\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0111 - val_loss: 0.0283\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0111 - val_loss: 0.0283\n",
      "Epoch 50/100\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0109 - val_loss: 0.0283\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0107 - val_loss: 0.0282\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0112 - val_loss: 0.0283\n",
      "Epoch 53/100\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0110 - val_loss: 0.0283\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0106 - val_loss: 0.0282\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0108 - val_loss: 0.0282\n",
      "Epoch 56/100\n",
      "3125/3125 [==============================] - 4s 1ms/step - loss: 0.0109 - val_loss: 0.0282\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0111 - val_loss: 0.0283\n",
      "Epoch 58/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0111 - val_loss: 0.0282\n",
      "Epoch 59/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0110 - val_loss: 0.0282\n",
      "Epoch 60/100\n",
      "3125/3125 [==============================] - 9s 3ms/step - loss: 0.0110 - val_loss: 0.0282\n",
      "Epoch 61/100\n",
      "3125/3125 [==============================] - 7s 2ms/step - loss: 0.0109 - val_loss: 0.0282\n",
      "Epoch 62/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0109 - val_loss: 0.0282\n",
      "Epoch 63/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0107 - val_loss: 0.0282\n",
      "Epoch 64/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0109 - val_loss: 0.0282\n",
      "Epoch 65/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0282\n",
      "Epoch 66/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0110 - val_loss: 0.0282\n",
      "Epoch 67/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0282\n",
      "Epoch 68/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0107 - val_loss: 0.0282\n",
      "Epoch 69/100\n",
      "3125/3125 [==============================] - 6s 2ms/step - loss: 0.0111 - val_loss: 0.0282\n",
      "Epoch 70/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0107 - val_loss: 0.0282\n",
      "Epoch 71/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0107 - val_loss: 0.0282\n",
      "Epoch 72/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0110 - val_loss: 0.0282\n",
      "Epoch 73/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0282\n",
      "Epoch 74/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0111 - val_loss: 0.0282\n",
      "Epoch 75/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0282\n",
      "Epoch 76/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0282\n",
      "Epoch 77/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0282\n",
      "Epoch 78/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0107 - val_loss: 0.0282\n",
      "Epoch 79/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0282\n",
      "Epoch 80/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0281\n",
      "Epoch 81/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0107 - val_loss: 0.0281\n",
      "Epoch 82/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0110 - val_loss: 0.0281\n",
      "Epoch 83/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0281\n",
      "Epoch 84/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0107 - val_loss: 0.0281\n",
      "Epoch 85/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0107 - val_loss: 0.0282\n",
      "Epoch 86/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0107 - val_loss: 0.0282\n",
      "Epoch 87/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0110 - val_loss: 0.0282\n",
      "Epoch 88/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0110 - val_loss: 0.0282\n",
      "Epoch 89/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0282\n",
      "Epoch 90/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0282\n",
      "Epoch 91/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0282\n",
      "Epoch 92/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0110 - val_loss: 0.0281\n",
      "Epoch 93/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0106 - val_loss: 0.0281\n",
      "Epoch 94/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0281\n",
      "Epoch 95/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0281\n",
      "Epoch 96/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0281\n",
      "Epoch 97/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0281\n",
      "Epoch 98/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0108 - val_loss: 0.0281\n",
      "Epoch 99/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0107 - val_loss: 0.0281\n",
      "Epoch 100/100\n",
      "3125/3125 [==============================] - 5s 2ms/step - loss: 0.0109 - val_loss: 0.0281\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# Deep - AE\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "pretrain_features_size = 10\n",
    "target_dim_size = 32\n",
    "autoencoder = Autoencoder()\n",
    "opt = optimizers.Adam(lr=0.0001)\n",
    "autoencoder.build_deep_ae(pretrain_features_size, target_dim_size, opt)\n",
    "\n",
    "history = autoencoder.train(features, features, features_test, features_test,\n",
    "                 epochs=100,\n",
    "                 batch_size=16,\n",
    "                 shuffle=True)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Deep Autoencoder')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "autoencoder.save('model-ae/deep-ae-decoder.h5', 'model-ae/deep-ae-encoder.h5')\n",
    "print (\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0f20261183e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtarget_dim_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_conv_ae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain_features_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dim_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m history = autoencoder.train(features, features, features_test, features_test,\n",
      "\u001b[0;32m<ipython-input-1-c04c1f2a0875>\u001b[0m in \u001b[0;36mbuild_conv_ae\u001b[0;34m(self, input_dims, encoding_dim)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_conv_ae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mconv_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mpool_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconv_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mconv_two\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpool_one\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 971\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1107\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1109\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    877\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2601\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2602\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2603\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2604\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 10)"
     ]
    }
   ],
   "source": [
    "# Convolutional - AE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pretrain_features_size = 10\n",
    "target_dim_size = 32\n",
    "autoencoder = Autoencoder()\n",
    "autoencoder.build_conv_ae(pretrain_features_size, target_dim_size)\n",
    "\n",
    "history = autoencoder.train(features, features, features_test, features_test,\n",
    "                 epochs=100,\n",
    "                 batch_size=16,\n",
    "                 shuffle=True)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Convolutional Autoencoder')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "autoencoder.save('model-ae/conv-ae-decoder.h5', 'model-ae/conv-ae-encoder.h5')\n",
    "print (\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
