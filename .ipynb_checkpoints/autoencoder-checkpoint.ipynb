{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "# from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,\\\n",
    "#                                     Add, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "class Autoencoder:\n",
    "    def __init__(self):\n",
    "        self.encoder_model = None\n",
    "        self.model = None\n",
    "        return\n",
    "    \n",
    "    def build_simple_ae(self, input_dim, encoding_dim):\n",
    "        input_layer = Input(shape=(input_dim,))\n",
    "        encoder_output = Dense(encoding_dim, activation='relu') (input_layer)\n",
    "        self.encoder_model = Model(input_layer, encoder_output)\n",
    "        decoder_output = Dense(input_dim, activation='sigmoid') (encoder_output)\n",
    "        self.model = Model(input_layer, decoder_output)\n",
    "        self.model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "        return\n",
    "    \n",
    "    def build_deep_ae(self, input_dim, encoding_dim, opt):\n",
    "        input_layer = Input(shape=(input_dim,))\n",
    "        \n",
    "        hidden_one = Dense(encoding_dim*4, activation='relu') (input_layer)\n",
    "        hidden_two = Dense(encoding_dim*2, activation='relu') (hidden_one)\n",
    "        encoder_output = Dense(encoding_dim, activation='relu') (hidden_two)\n",
    "        self.encoder_model = Model(input_layer, encoder_output)\n",
    "        \n",
    "        hidden_three = Dense(encoding_dim*2, activation='relu') (encoder_output)\n",
    "        hidden_four = Dense(encoding_dim*4, activation='relu') (hidden_three)\n",
    "        decoder_output = Dense(input_dim, activation='sigmoid') (hidden_four)\n",
    "        self.model = Model(input_layer, decoder_output)\n",
    "        \n",
    "        self.model.compile(optimizer=opt, loss='binary_crossentropy', )\n",
    "        return\n",
    "    \n",
    "    def build_conv_ae(self, input_dims, encoding_dim):\n",
    "        input_layer = Input(shape=input_dims)\n",
    "        conv_one = Conv2D(16, (3,3), activation='relu', padding='same') (input_layer)\n",
    "        pool_one = MaxPooling2D((2,2), padding='same') (conv_one)\n",
    "        conv_two = Conv2D(8, (3,3), activation='relu', padding='same') (pool_one)\n",
    "        pool_two = MaxPooling2D((2,2), padding='same') (conv_two)\n",
    "        conv_three = Conv2D(8, (3,3), activation='relu', padding='same') (pool_two)\n",
    "        encoder_output = MaxPooling2D((2,2), padding='same') (conv_three)\n",
    "        self.encoder_model = Model(input_layer, encoder_output)\n",
    "        \n",
    "        conv_four = Conv2D(8, (3,3), activation='relu', padding='same') (encoder_output)\n",
    "        upsamp_one = UpSampling2D((2,2)) (conv_four)\n",
    "        conv_five = Conv2D(8, (3,3), activation='relu', padding='same') (upsamp_one)\n",
    "        upsamp_two = UpSampling2D((2,2)) (conv_five)\n",
    "        conv_six = Conv2D(16, (3,3), activation='relu') (upsamp_two)\n",
    "        upsamp_three = UpSampling2D((2,2)) (conv_six)\n",
    "        decoder_output = Conv2D(1, (3,3), activation='sigmoid', padding='same') (upsamp_three)\n",
    "        self.model = Model(input_layer, decoder_output)\n",
    "        \n",
    "        self.model.compile(optimizer='adagrad', loss='binary_crossentropy')\n",
    "        return\n",
    "    \n",
    "    def load(self, model_file, encoder_model_file):\n",
    "        self.encoder_model = load_model(encoder_model_file)\n",
    "        self.model = load_model(model_file)\n",
    "        return\n",
    "    \n",
    "    def train(self, train_input, train_output,\n",
    "             val_input, val_output,\n",
    "             epochs=50,\n",
    "             batch_size=256,\n",
    "             shuffle=True):\n",
    "        history = self.model.fit(train_input, train_output,\n",
    "                      epochs=epochs, batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(val_input, val_output),\n",
    "                      )\n",
    "        return history\n",
    "    \n",
    "    def encoder_predict(self, test_input):\n",
    "        return self.encoder_model.predict(test_input)\n",
    "    \n",
    "    def predict(self, test_input):\n",
    "        return self.model.predict(test_input)\n",
    "    \n",
    "    def save(self, model_file, encoder_model_file):\n",
    "        self.model.save(model_file)\n",
    "        self.encoder_model.save(encoder_model_file)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = load_model('extractor.h5', compile=False)\n",
    "print (\"Loaded pre-trained convolution layers!\")\n",
    "\n",
    "features = feature_extractor.predict(x_train)\n",
    "features_test = feature_extractor.predict(x_test)\n",
    "\n",
    "print (features.shape)\n",
    "print (features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple - AE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pretrain_features_size = 10\n",
    "target_dim_size = 32\n",
    "autoencoder = Autoencoder()\n",
    "autoencoder.build_simple_ae(pretrain_features_size, target_dim_size)\n",
    "\n",
    "history = autoencoder.train(features, features, features_test, features_test,\n",
    "                 epochs=100,\n",
    "                 batch_size=16,\n",
    "                 shuffle=True)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Simple Autoencoder')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "autoencoder.save('simple-ae-decoder.h5', 'simple-ae-encoder.h5')\n",
    "print (\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep - AE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pretrain_features_size = 10\n",
    "target_dim_size = 32\n",
    "autoencoder = Autoencoder()\n",
    "opt = optimizers.Adam(lr=0.0001)\n",
    "autoencoder.build_deep_ae(pretrain_features_size, target_dim_size, opt)\n",
    "\n",
    "history = autoencoder.train(features, features, features_test, features_test,\n",
    "                 epochs=100,\n",
    "                 batch_size=16,\n",
    "                 shuffle=True)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Deep Autoencoder')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "autoencoder.save('deep-ae-decoder.h5', 'deep-ae-encoder.h5')\n",
    "print (\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional - AE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pretrain_features_size = 10\n",
    "target_dim_size = 32\n",
    "autoencoder = Autoencoder()\n",
    "autoencoder.build_conv_ae(pretrain_features_size, target_dim_size)\n",
    "\n",
    "history = autoencoder.train(features, features, features_test, features_test,\n",
    "                 epochs=100,\n",
    "                 batch_size=16,\n",
    "                 shuffle=True)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Convolutional Autoencoder')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "autoencoder.save('conv-ae-decoder.h5', 'conv-ae-encoder.h5')\n",
    "print (\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
