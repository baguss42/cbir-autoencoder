{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "cifar loaded!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from annoy import AnnoyIndex\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(y_train)\n",
    "y_train = enc.transform(y_train).toarray()\n",
    "\n",
    "print(\"cifar loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "lookup = np.argmax(y_train[:, :], axis=1)\n",
    "lookup_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate(idx, kind):\n",
    "#     vector_name = \"\";\n",
    "#     if kind==\"cnn\":\n",
    "#         vector_name = \"features\"\n",
    "#     elif kind==\"simple\":\n",
    "#         vector_name = \"vectors-simple\"\n",
    "#     elif kind==\"sparse\":\n",
    "#         vector_name = \"vectors-sparse\"\n",
    "#     elif kind==\"deep\":\n",
    "#         vector_name = \"vectors-deep\"\n",
    "#     elif kind==\"denoising\":\n",
    "#         vector_name = \"vectors-denoising\"\n",
    "    \n",
    "#     pickle_in = open(\"model-features/cbir-resnet-\" + vector_name + \".pickle\", \"rb\")\n",
    "#     vectors = pickle.load(pickle_in)\n",
    "#     index = AnnoyIndex(vectors.shape[1], metric='angular')\n",
    "#     for i in range(vectors.shape[0]):\n",
    "#         index.add_item(i, vectors[i,:].tolist())\n",
    "#     index.build(20)\n",
    "#     results = index.get_nns_by_item(idx, 5000)\n",
    "#     t = np.ones(5000).astype(float)\n",
    "#     p = np.array([lookup[x] == lookup[idx] for x in results]).astype(float)\n",
    "#     result = [round(f1_score(t, p),3), round(precision_score(t, p),3), round(recall_score(t, p),3)]\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(idx, kind):\n",
    "    vector_name = \"\";\n",
    "    if kind==\"cnn\":\n",
    "        vector_name = \"features\"\n",
    "    elif kind==\"simple\":\n",
    "        vector_name = \"vectors-simple\"\n",
    "    elif kind==\"sparse\":\n",
    "        vector_name = \"vectors-sparse\"\n",
    "    elif kind==\"deep\":\n",
    "        vector_name = \"vectors-deep\"\n",
    "    elif kind==\"denoising\":\n",
    "        vector_name = \"vectors-denoising\"\n",
    "    \n",
    "    pickle_features = open(\"pickle-test/cbir-resnet-\" + vector_name + \"-test.pickle\", \"rb\")\n",
    "    features = pickle.load(pickle_features)\n",
    "    index = AnnoyIndex(features.shape[1], metric='angular')\n",
    "    for i in range(features.shape[0]):\n",
    "        index.add_item(i, features[i,:].tolist())\n",
    "    index.build(20)\n",
    "#     results = index.get_nns_by_item(idx, 5000))\n",
    "    results = index.get_nns_by_vector(features[idx], 1000)\n",
    "    t = np.ones(1000).astype(float)\n",
    "    p = np.array([lookup_test[x] == lookup_test[idx] for x in results]).astype(float)\n",
    "#     result = [round(f1_score(t, p),3), round(precision_score(t, p),3), round(recall_score(t, p),3)]\n",
    "    result = round(accuracy_score(t, p),3)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2 s.\n",
      "1   2 s.\n",
      "2   2 s.\n",
      "3   2 s.\n",
      "4   2 s.\n",
      "5   2 s.\n",
      "6   2 s.\n",
      "7   2 s.\n",
      "8   2 s.\n",
      "9   2 s.\n",
      "Done calculate !!!\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "categories = y_test.flatten()\n",
    "result = []\n",
    "for y in range(10):\n",
    "    cnn = []\n",
    "    simple = []\n",
    "    sparse = []\n",
    "    deep = []\n",
    "    denoising = []\n",
    "    count = 0\n",
    "    idx_cat = [i for i, e in enumerate(categories) if e == y]\n",
    "    start = timer()\n",
    "    for i in idx_cat[0:2]:\n",
    "        count += 1\n",
    "        cnn.append(calculate(i, \"cnn\"))\n",
    "        simple.append(calculate(i, \"simple\"))\n",
    "        sparse.append(calculate(i, \"sparse\"))\n",
    "        deep.append(calculate(i, \"deep\"))\n",
    "        denoising.append(calculate(i, \"denoising\"))\n",
    "#     data = {\n",
    "#         \"cnn\": np.sum(cnn, axis = 0),\n",
    "#         \"simple\": np.sum(simple, axis = 0),\n",
    "#         \"sparse\": np.sum(sparse, axis = 0),\n",
    "#         \"deep\": np.sum(deep, axis = 0),\n",
    "#         \"denoising\": np.sum(denoising, axis = 0),\n",
    "#     }\n",
    "    data = {\n",
    "        \"cnn\": cnn,\n",
    "        \"simple\": simple,\n",
    "        \"sparse\": sparse,\n",
    "        \"deep\": deep,\n",
    "        \"denoising\": denoising,\n",
    "    }\n",
    "    result.append(data)\n",
    "    end = timer()\n",
    "    print(y, \" \", round(end - start), \"s.\")\n",
    "print(\"Done calculate !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'cnn': [0.809, 0.795],\n",
       "  'simple': [0.826, 0.832],\n",
       "  'sparse': [0.843, 0.843],\n",
       "  'deep': [0.788, 0.848],\n",
       "  'denoising': [0.831, 0.834]},\n",
       " {'cnn': [0.942, 0.942],\n",
       "  'simple': [0.943, 0.943],\n",
       "  'sparse': [0.942, 0.942],\n",
       "  'deep': [0.931, 0.92],\n",
       "  'denoising': [0.943, 0.943]},\n",
       " {'cnn': [0.792, 0.794],\n",
       "  'simple': [0.792, 0.197],\n",
       "  'sparse': [0.793, 0.187],\n",
       "  'deep': [0.784, 0.503],\n",
       "  'denoising': [0.794, 0.238]},\n",
       " {'cnn': [0.721, 0.721],\n",
       "  'simple': [0.73, 0.73],\n",
       "  'sparse': [0.731, 0.731],\n",
       "  'deep': [0.602, 0.595],\n",
       "  'denoising': [0.73, 0.73]},\n",
       " {'cnn': [0.782, 0.784],\n",
       "  'simple': [0.832, 0.831],\n",
       "  'sparse': [0.833, 0.833],\n",
       "  'deep': [0.78, 0.813],\n",
       "  'denoising': [0.794, 0.798]},\n",
       " {'cnn': [0.024, 0.785],\n",
       "  'simple': [0.038, 0.8],\n",
       "  'sparse': [0.034, 0.803],\n",
       "  'deep': [0.064, 0.789],\n",
       "  'denoising': [0.027, 0.804]},\n",
       " {'cnn': [0.844, 0.843],\n",
       "  'simple': [0.874, 0.874],\n",
       "  'sparse': [0.871, 0.872],\n",
       "  'deep': [0.867, 0.864],\n",
       "  'denoising': [0.869, 0.869]},\n",
       " {'cnn': [0.887, 0.887],\n",
       "  'simple': [0.893, 0.893],\n",
       "  'sparse': [0.892, 0.892],\n",
       "  'deep': [0.889, 0.889],\n",
       "  'denoising': [0.893, 0.893]},\n",
       " {'cnn': [0.905, 0.017],\n",
       "  'simple': [0.906, 0.018],\n",
       "  'sparse': [0.905, 0.017],\n",
       "  'deep': [0.908, 0.64],\n",
       "  'denoising': [0.907, 0.019]},\n",
       " {'cnn': [0.877, 0.877],\n",
       "  'simple': [0.894, 0.894],\n",
       "  'sparse': [0.891, 0.891],\n",
       "  'deep': [0.921, 0.921],\n",
       "  'denoising': [0.888, 0.888]}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    F1-Score Precision    Recall\n",
      "cnn              :  0.7514000000000001\n",
      "cnn-simple-ae    :  0.7370000000000001\n",
      "cnn-sparse-ae    :  0.7373\n",
      "cnn-deep-ae      :  0.7657999999999999\n",
      "cnn-denoising-ae :  0.7346\n"
     ]
    }
   ],
   "source": [
    "arr_cnn = []\n",
    "arr_simple = []\n",
    "arr_sparse = []\n",
    "arr_deep = []\n",
    "arr_denoising = []\n",
    "for arr in result:\n",
    "    arr_cnn.append(arr['cnn'])\n",
    "    arr_simple.append(arr['simple'])\n",
    "    arr_sparse.append(arr['sparse'])\n",
    "    arr_deep.append(arr['deep'])\n",
    "    arr_denoising.append(arr['denoising'])\n",
    "mean_cnn = np.mean(np.array(arr_cnn))\n",
    "mean_simple = np.mean(np.array(arr_simple))\n",
    "mean_sparse = np.mean(np.array(arr_sparse))\n",
    "mean_deep = np.mean(np.array(arr_deep))\n",
    "mean_denoising = np.mean(np.array(arr_denoising))\n",
    "print(\"                    F1-Score Precision    Recall\")\n",
    "print(\"cnn              : \", mean_cnn)\n",
    "print(\"cnn-simple-ae    : \", mean_simple)\n",
    "print(\"cnn-sparse-ae    : \", mean_sparse)\n",
    "print(\"cnn-deep-ae      : \", mean_deep)\n",
    "print(\"cnn-denoising-ae : \", mean_denoising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.998 1.    0.996]\n",
      "[0.998 1.    0.996]\n",
      "[0.998 1.    0.996]\n",
      "[0.997 1.    0.995]\n",
      "[0.998 1.    0.996]\n"
     ]
    }
   ],
   "source": [
    "sum_cnn = np.sum(cnn, axis = 0)\n",
    "print(sum_cnn)\n",
    "sum_simple = np.sum(simple, axis = 0)\n",
    "print(sum_simple)\n",
    "sum_sparse = np.sum(sparse, axis = 0)\n",
    "print(sum_sparse)\n",
    "sum_deep = np.sum(deep, axis = 0)\n",
    "print(sum_deep)\n",
    "sum_denoising = np.sum(denoising, axis = 0)\n",
    "print(sum_denoising)\n",
    "sum_cnn = np.sum(cnn, axis = 0)\n",
    "print(sum_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15  6  9]\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "arr = [[5,2,3],[5,2,3],[5,2,3]]\n",
    "sum_arr = np.sum(arr, axis = 0)\n",
    "print(sum_arr)\n",
    "print(sum_arr[0]/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
