{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-trained convolution layers!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "feature_extractor = load_model('extractor.h5')\n",
    "print (\"Loaded pre-trained convolution layers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 32, 32, 3)\n",
      "(4000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "interested = [0, 1, 8, 9]\n",
    "\n",
    "scrap = []\n",
    "for idx, im in enumerate(x_train):\n",
    "    if (y_train[idx][0] not in interested):\n",
    "        scrap.append(idx)\n",
    "        \n",
    "x_train = np.delete(x_train, scrap, axis=0)\n",
    "y_train = np.delete(y_train, scrap, axis=0)\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(y_train)\n",
    "y_train = enc.transform(y_train).toarray()\n",
    "\n",
    "scrap = []\n",
    "for idx, im in enumerate(x_test):\n",
    "    if (y_test[idx][0] not in interested):\n",
    "        scrap.append(idx)\n",
    "x_test = np.delete(x_test, scrap, axis=0)\n",
    "y_test = np.delete(y_test, scrap, axis=0)\n",
    "y_test = enc.transform(y_test).toarray()\n",
    "\n",
    "x_train = (x_train.astype('float32')) / 255.0\n",
    "x_test = (x_test.astype('float32')) / 255.0\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 4)\n",
      "(4000, 4)\n"
     ]
    }
   ],
   "source": [
    "features = feature_extractor.predict(x_train)\n",
    "features_test = feature_extractor.predict(x_test)\n",
    "\n",
    "print (features.shape)\n",
    "print (features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "class DeepAutoencoder:\n",
    "    def __init__(self):\n",
    "        self.encoder_model = None\n",
    "        self.model = None\n",
    "        return\n",
    "    \n",
    "    def build(self, input_dim, encoding_dim, opt):\n",
    "        input_layer = Input(shape=(input_dim,))\n",
    "        \n",
    "        hidden_one = Dense(encoding_dim*4, activation='relu') (input_layer)\n",
    "        hidden_two = Dense(encoding_dim*2, activation='relu') (hidden_one)\n",
    "        encoder_output = Dense(encoding_dim, activation='relu') (hidden_two)\n",
    "        self.encoder_model = Model(input_layer, encoder_output)\n",
    "        \n",
    "        hidden_three = Dense(encoding_dim*2, activation='relu') (encoder_output)\n",
    "        hidden_four = Dense(encoding_dim*4, activation='relu') (hidden_three)\n",
    "        decoder_output = Dense(input_dim, activation='sigmoid') (hidden_four)\n",
    "        self.model = Model(input_layer, decoder_output)\n",
    "        \n",
    "        self.model.compile(optimizer=opt, loss='binary_crossentropy', )\n",
    "\n",
    "\n",
    "        # This is the size of our encoded representations\n",
    "#         encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "#         # This is our input image\n",
    "#         input_img = Input(shape=(784,))\n",
    "#         # \"encoded\" is the encoded representation of the input\n",
    "#         encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "#         # \"decoded\" is the lossy reconstruction of the input\n",
    "#         decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "#         # This model maps an input to its reconstruction\n",
    "#         self.model = Model(input_img, decoded)\n",
    "#         # This model maps an input to its encoded representation\n",
    "#         self.encoder_model = Model(input_img, encoded)\n",
    "#         # This is our encoded (32-dimensional) input\n",
    "#         encoded_input = Input(shape=(encoding_dim,))\n",
    "#         # Retrieve the last layer of the autoencoder model\n",
    "#         decoder_layer = self.model.layers[-1]\n",
    "#         # Create the decoder model\n",
    "#         decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "#         self.model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "        return\n",
    "    \n",
    "    def load(self, model_file, encoder_model_file):\n",
    "        self.encoder_model = load_model(encoder_model_file)\n",
    "        self.model = load_model(model_file)\n",
    "        return\n",
    "    \n",
    "    def train(self, train_input, train_output,\n",
    "             val_input, val_output,\n",
    "             epochs=50,\n",
    "             batch_size=256,\n",
    "             shuffle=True):\n",
    "        tensorboard = TensorBoard(log_dir='./tf_logs_two', histogram_freq=0, write_graph=True, write_images=False)\n",
    "        self.model.fit(train_input, train_output,\n",
    "                      epochs=epochs, batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(val_input, val_output),\n",
    "                      callbacks=[tensorboard]\n",
    "                      )\n",
    "        return\n",
    "    \n",
    "    def encoder_predict(self, test_input):\n",
    "        return self.encoder_model.predict(test_input)\n",
    "    \n",
    "    def predict(self, test_input):\n",
    "        return self.model.predict(test_input)\n",
    "    \n",
    "    def save(self, model_file, encoder_model_file):\n",
    "        self.model.save(model_file)\n",
    "        self.encoder_model.save(encoder_model_file)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "pretrain_features_size = 4\n",
    "target_dim_size = 32\n",
    "autoencoder = DeepAutoencoder()\n",
    "opt = optimizers.Adam(lr=0.0001)\n",
    "autoencoder.build(pretrain_features_size, target_dim_size, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 4000 samples\n",
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 2s 80us/sample - loss: 0.6687 - val_loss: 0.6358\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.5694 - val_loss: 0.4939\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.3983 - val_loss: 0.3099\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.1902 - val_loss: 0.1330\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0600 - val_loss: 0.0715\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0230 - val_loss: 0.0592\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.0130 - val_loss: 0.0572\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0094 - val_loss: 0.0575\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 0s 20us/sample - loss: 0.0078 - val_loss: 0.0584\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 0s 18us/sample - loss: 0.0070 - val_loss: 0.0595\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.0065 - val_loss: 0.0605\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0062 - val_loss: 0.0614\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0061 - val_loss: 0.0622\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0059 - val_loss: 0.0628\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0058 - val_loss: 0.0635\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0058 - val_loss: 0.0642\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0057 - val_loss: 0.0646\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0057 - val_loss: 0.0649\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 0s 20us/sample - loss: 0.0057 - val_loss: 0.0652\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0057 - val_loss: 0.0656\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 0s 15us/sample - loss: 0.0056 - val_loss: 0.0657\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0056 - val_loss: 0.0660\n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0056 - val_loss: 0.0660\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 0s 18us/sample - loss: 0.0056 - val_loss: 0.0662\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0056 - val_loss: 0.0659\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0056 - val_loss: 0.0663\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0056 - val_loss: 0.0663\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 0s 19us/sample - loss: 0.0056 - val_loss: 0.0663\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 0s 21us/sample - loss: 0.0056 - val_loss: 0.0663\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 0s 21us/sample - loss: 0.0056 - val_loss: 0.0662\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0056 - val_loss: 0.0665\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0056 - val_loss: 0.0662\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0056 - val_loss: 0.0663\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0055 - val_loss: 0.0663\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0055 - val_loss: 0.0662\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0055 - val_loss: 0.0663\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0055 - val_loss: 0.0662\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 0s 20us/sample - loss: 0.0055 - val_loss: 0.0662\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 0s 19us/sample - loss: 0.0055 - val_loss: 0.0661\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 0s 20us/sample - loss: 0.0055 - val_loss: 0.0662\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 0s 18us/sample - loss: 0.0055 - val_loss: 0.0661\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 0s 19us/sample - loss: 0.0055 - val_loss: 0.0658\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0055 - val_loss: 0.0657\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0055 - val_loss: 0.0659\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0055 - val_loss: 0.0658\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 0s 19us/sample - loss: 0.0055 - val_loss: 0.0655\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 0s 18us/sample - loss: 0.0055 - val_loss: 0.0655\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 0s 16us/sample - loss: 0.0055 - val_loss: 0.0656\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0055 - val_loss: 0.0653\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 0s 17us/sample - loss: 0.0055 - val_loss: 0.0651\n"
     ]
    }
   ],
   "source": [
    "autoencoder.train(features, features, features_test, features_test,\n",
    "                 epochs=50,\n",
    "                 batch_size=256,\n",
    "                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save('ae-complete.h5', 'ae-encoder.h5')\n",
    "print (\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
