{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "class ConvolutionalAutoencoder:\n",
    "    def __init__(self):\n",
    "        self.encoder_model = None\n",
    "        self.model = None\n",
    "        return\n",
    "    \n",
    "    def build(self, input_dims, encoding_dim):\n",
    "        input_layer = Input(shape=input_dims)\n",
    "        \n",
    "        conv_one = Conv2D(16, (3,3), activation='relu', padding='same') (input_layer)\n",
    "        pool_one = MaxPooling2D((2,2), padding='same') (conv_one)\n",
    "        conv_two = Conv2D(8, (3,3), activation='relu', padding='same') (pool_one)\n",
    "        pool_two = MaxPooling2D((2,2), padding='same') (conv_two)\n",
    "        conv_three = Conv2D(8, (3,3), activation='relu', padding='same') (pool_two)\n",
    "        encoder_output = MaxPooling2D((2,2), padding='same') (conv_three)\n",
    "        self.encoder_model = Model(input_layer, encoder_output)\n",
    "        \n",
    "        conv_four = Conv2D(8, (3,3), activation='relu', padding='same') (encoder_output)\n",
    "        upsamp_one = UpSampling2D((2,2)) (conv_four)\n",
    "        conv_five = Conv2D(8, (3,3), activation='relu', padding='same') (upsamp_one)\n",
    "        upsamp_two = UpSampling2D((2,2)) (conv_five)\n",
    "        conv_six = Conv2D(16, (3,3), activation='relu') (upsamp_two)\n",
    "        upsamp_three = UpSampling2D((2,2)) (conv_six)\n",
    "        decoder_output = Conv2D(1, (3,3), activation='sigmoid', padding='same') (upsamp_three)\n",
    "        self.model = Model(input_layer, decoder_output)\n",
    "        \n",
    "        self.model.compile(optimizer='adagrad', loss='binary_crossentropy')\n",
    "        return\n",
    "    \n",
    "    def load(self, model_file, encoder_model_file):\n",
    "        self.encoder_model = load_model(encoder_model_file)\n",
    "        self.model = load_model(model_file)\n",
    "        return\n",
    "    \n",
    "    def train(self, train_input, train_output,\n",
    "             val_input, val_output,\n",
    "             epochs=50,\n",
    "             batch_size=256,\n",
    "             shuffle=True):\n",
    "        self.model.fit(train_input, train_output,\n",
    "                      epochs=epochs, batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      validation_data=(val_input, val_output))\n",
    "        return\n",
    "    \n",
    "    def encoder_predict(self, test_input):\n",
    "        return self.encoder_model.predict(test_input)\n",
    "    \n",
    "    def predict(self, test_input):\n",
    "        return self.model.predict(test_input)\n",
    "    \n",
    "    def save(self, model_file, encoder_model_file):\n",
    "        self.model.save(model_file)\n",
    "        self.encoder_model.save(encoder_model_file)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "print x_train.shape\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = ConvolutionalAutoencoder()\n",
    "autoencoder.build((28, 28, 1, ), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 26s - loss: 0.2233 - val_loss: 0.1799\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1716 - val_loss: 0.1646\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1594 - val_loss: 0.1551\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1520 - val_loss: 0.1500\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1466 - val_loss: 0.1423\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1423 - val_loss: 0.1389\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1391 - val_loss: 0.1374\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1365 - val_loss: 0.1337\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1345 - val_loss: 0.1333\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1328 - val_loss: 0.1312\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1312 - val_loss: 0.1292\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1299 - val_loss: 0.1279\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1289 - val_loss: 0.1267\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1277 - val_loss: 0.1258\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1268 - val_loss: 0.1248\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1259 - val_loss: 0.1241\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1250 - val_loss: 0.1237\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1244 - val_loss: 0.1226\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1237 - val_loss: 0.1219\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1230 - val_loss: 0.1212\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1223 - val_loss: 0.1206\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1217 - val_loss: 0.1207\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 23s - loss: 0.1212 - val_loss: 0.1198\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1207 - val_loss: 0.1192\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1201 - val_loss: 0.1186\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1196 - val_loss: 0.1180\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1192 - val_loss: 0.1175\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1187 - val_loss: 0.1173\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1183 - val_loss: 0.1168\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1179 - val_loss: 0.1167\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1174 - val_loss: 0.1160\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1170 - val_loss: 0.1156\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1166 - val_loss: 0.1151\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1163 - val_loss: 0.1148\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 20s - loss: 0.1160 - val_loss: 0.1144\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1157 - val_loss: 0.1141\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 23s - loss: 0.1153 - val_loss: 0.1141\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 23s - loss: 0.1150 - val_loss: 0.1135\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 24s - loss: 0.1147 - val_loss: 0.1132\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 25s - loss: 0.1145 - val_loss: 0.1129\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 23s - loss: 0.1141 - val_loss: 0.1126\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1138 - val_loss: 0.1124\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1136 - val_loss: 0.1121\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1134 - val_loss: 0.1119\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1131 - val_loss: 0.1116\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 22s - loss: 0.1129 - val_loss: 0.1114\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1126 - val_loss: 0.1113\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1124 - val_loss: 0.1109\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1121 - val_loss: 0.1113\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 21s - loss: 0.1119 - val_loss: 0.1105\n"
     ]
    }
   ],
   "source": [
    "autoencoder.train(x_train, x_train, x_test, x_test,\n",
    "                 epochs=50,\n",
    "                 batch_size=256,\n",
    "                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_train = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAADsCAYAAAB37KKJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2v8BHENoKCuaqRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f54dffbcbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(5):\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax = plt.subplot(2, 5, i+1+5)\n",
    "    plt.imshow(pred_train[i].reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "autoencoder.model.save('conv-autoencoder-model.h5')\n",
    "autoencoder.encoder_model.save('conv-autoencoder-encoder-model.h5')\n",
    "print \"Saved!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
