{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, Reshape, MaxPooling2D, UpSampling2D, Flatten, BatchNormalization, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        self.encoder_model = None\n",
    "        self.model = None\n",
    "        return\n",
    "    \n",
    "    def build(self, input_dims, opt):\n",
    "        input_layer = Input(shape=input_dims)\n",
    "        \n",
    "        a_one = Conv2D(64, (3,3), activation='relu', padding='same') (input_layer)\n",
    "        #a_two = BatchNormalization() (a_one)\n",
    "        a_three = Conv2D(64, (3,3), activation='relu', padding='same') (a_one)\n",
    "        #a_four = BatchNormalization() (a_three)\n",
    "        a_five = MaxPooling2D() (a_three)\n",
    "        block_one = Dropout(0.25) (a_five)\n",
    "        #block_one = a_five\n",
    "        \n",
    "        b_one = Conv2D(128, (3,3), activation='relu', padding='same') (block_one)\n",
    "        #b_two = BatchNormalization() (b_one)\n",
    "        b_three = Conv2D(128, (3,3), activation='relu', padding='same') (b_one)\n",
    "        #b_four = BatchNormalization() (b_two)\n",
    "        b_five = MaxPooling2D() (b_three)\n",
    "        block_two = Dropout(0.25) (b_five)\n",
    "        \n",
    "        c_one = Conv2D(256, (3,3), activation='relu', padding='same') (block_two)\n",
    "        #c_two = BatchNormalization() (c_one)\n",
    "        c_three = Conv2D(256, (3,3), activation='relu', padding='same') (c_one)\n",
    "        #c_four = BatchNormalization() (c_three)\n",
    "        c_five = MaxPooling2D() (c_three)\n",
    "        block_three = Dropout(0.5) (c_five)\n",
    "        \n",
    "        d_one = Conv2D(512, (3,3), activation='relu', padding='same') (block_three)\n",
    "        #d_two = BatchNormalization() (d_one)\n",
    "        d_three = Conv2D(512, (1,1), activation='relu', padding='same') (d_one)\n",
    "        #d_four = BatchNormalization() (d_three)\n",
    "        d_five = MaxPooling2D() (d_three)\n",
    "        block_four = Dropout(0.2) (d_five)\n",
    "        \n",
    "        flat = Flatten() (block_four)\n",
    "        fc_one = Dense(4096, activation='relu') (flat)\n",
    "        #block_five = BatchNormalization() (fc_one)\n",
    "        \n",
    "        fc_two = Dense(4096, activation='relu') (fc_one)\n",
    "        #block_six = BatchNormalization() (fc_two)\n",
    "        \n",
    "        final = Dense(4, activation='softmax') (fc_two)\n",
    "        \n",
    "        self.model = Model(input_layer, final)\n",
    "        self.feature_extractor = Model(input_layer, flat)\n",
    "        self.model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return\n",
    "    \n",
    "    def load(self, model_file, encoder_model_file):\n",
    "        self.encoder_model = load_model(encoder_model_file)\n",
    "        self.model = load_model(model_file)\n",
    "        return\n",
    "    \n",
    "    def train(self, train_input, train_output,\n",
    "             val_input, val_output,\n",
    "             epochs=50,\n",
    "             batch_size=64,\n",
    "             shuffle=True):\n",
    "        tensorboard = TensorBoard(log_dir='./tf_logs', histogram_freq=0, write_graph=True, write_images=False)\n",
    "        self.model.fit(train_input, train_output,\n",
    "                      epochs=epochs, batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      validation_data=(val_input, val_output),\n",
    "                      callbacks=[tensorboard])\n",
    "        return\n",
    "    \n",
    "    def encoder_predict(self, test_input):\n",
    "        return self.encoder_model.predict(test_input)\n",
    "    \n",
    "    def predict(self, test_input):\n",
    "        return self.model.predict(test_input)\n",
    "    \n",
    "    def save(self, model_file, encoder_model_file):\n",
    "        self.model.save(model_file)\n",
    "        self.encoder_model.save(encoder_model_file)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 32, 32, 3)\n",
      "(4000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "interested = [0, 1, 8, 9]\n",
    "\n",
    "scrap = []\n",
    "for idx, im in enumerate(x_train):\n",
    "    if (y_train[idx][0] not in interested):\n",
    "        scrap.append(idx)\n",
    "        \n",
    "x_train = np.delete(x_train, scrap, axis=0)\n",
    "y_train = np.delete(y_train, scrap, axis=0)\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(y_train)\n",
    "y_train = enc.transform(y_train).toarray()\n",
    "\n",
    "scrap = []\n",
    "for idx, im in enumerate(x_test):\n",
    "    if (y_test[idx][0] not in interested):\n",
    "        scrap.append(idx)\n",
    "x_test = np.delete(x_test, scrap, axis=0)\n",
    "y_test = np.delete(y_test, scrap, axis=0)\n",
    "y_test = enc.transform(y_test).toarray()\n",
    "\n",
    "x_train = (x_train.astype('float32')) / 255.0\n",
    "x_test = (x_test.astype('float32')) / 255.0\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor()\n",
    "opt = optimizers.Adam(lr=0.0001, decay=1e-6)\n",
    "#opt = optimizers.rmsprop()\n",
    "#opt = optimizers.SGD(lr=0.1, nesterov=True, momentum=0.9)\n",
    "fe.build((32, 32, 3, ), opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 338s 2s/step - loss: 1.2616 - accuracy: 0.3929 - val_loss: 1.1333 - val_accuracy: 0.4940\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 349s 2s/step - loss: 1.0746 - accuracy: 0.5208 - val_loss: 1.0060 - val_accuracy: 0.5630\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 358s 2s/step - loss: 0.9997 - accuracy: 0.5577 - val_loss: 0.9346 - val_accuracy: 0.5822\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 325s 2s/step - loss: 0.9258 - accuracy: 0.6008 - val_loss: 0.8766 - val_accuracy: 0.6338\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 328s 2s/step - loss: 0.8431 - accuracy: 0.6420 - val_loss: 0.8593 - val_accuracy: 0.6403\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.7809 - accuracy: 0.6787 - val_loss: 0.6919 - val_accuracy: 0.7160\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.7306 - accuracy: 0.7039 - val_loss: 0.6645 - val_accuracy: 0.7243\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 326s 2s/step - loss: 0.6976 - accuracy: 0.7218 - val_loss: 0.6289 - val_accuracy: 0.7433\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 324s 2s/step - loss: 0.6627 - accuracy: 0.7402 - val_loss: 0.6170 - val_accuracy: 0.7505\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 326s 2s/step - loss: 0.6232 - accuracy: 0.7568 - val_loss: 0.6507 - val_accuracy: 0.7460\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 326s 2s/step - loss: 0.6001 - accuracy: 0.7666 - val_loss: 0.5630 - val_accuracy: 0.7795\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 326s 2s/step - loss: 0.5728 - accuracy: 0.7780 - val_loss: 0.5304 - val_accuracy: 0.7945\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.5524 - accuracy: 0.7891 - val_loss: 0.4851 - val_accuracy: 0.8108\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.5155 - accuracy: 0.8006 - val_loss: 0.5399 - val_accuracy: 0.7855\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 326s 2s/step - loss: 0.5053 - accuracy: 0.8049 - val_loss: 0.4908 - val_accuracy: 0.8110\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 327s 2s/step - loss: 0.4817 - accuracy: 0.8138 - val_loss: 0.4727 - val_accuracy: 0.8215\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 326s 2s/step - loss: 0.4584 - accuracy: 0.8250 - val_loss: 0.4636 - val_accuracy: 0.8200\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 326s 2s/step - loss: 0.4476 - accuracy: 0.8275 - val_loss: 0.4474 - val_accuracy: 0.8307\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 327s 2s/step - loss: 0.4333 - accuracy: 0.8376 - val_loss: 0.4473 - val_accuracy: 0.8292\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 327s 2s/step - loss: 0.4247 - accuracy: 0.8367 - val_loss: 0.4318 - val_accuracy: 0.8438\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 328s 2s/step - loss: 0.4078 - accuracy: 0.8465 - val_loss: 0.4449 - val_accuracy: 0.8353\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.4005 - accuracy: 0.8459 - val_loss: 0.4211 - val_accuracy: 0.8465\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.3847 - accuracy: 0.8544 - val_loss: 0.4178 - val_accuracy: 0.8420\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.3715 - accuracy: 0.8596 - val_loss: 0.4185 - val_accuracy: 0.8450\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.3651 - accuracy: 0.8601 - val_loss: 0.4856 - val_accuracy: 0.8300\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 327s 2s/step - loss: 0.3502 - accuracy: 0.8702 - val_loss: 0.4101 - val_accuracy: 0.8528\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 325s 2s/step - loss: 0.3437 - accuracy: 0.8689 - val_loss: 0.4003 - val_accuracy: 0.8565\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 327s 2s/step - loss: 0.3331 - accuracy: 0.8717 - val_loss: 0.4469 - val_accuracy: 0.8455\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 326s 2s/step - loss: 0.3281 - accuracy: 0.8723 - val_loss: 0.4227 - val_accuracy: 0.8518\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 327s 2s/step - loss: 0.3205 - accuracy: 0.8754 - val_loss: 0.4198 - val_accuracy: 0.8608\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 331s 2s/step - loss: 0.3081 - accuracy: 0.8816 - val_loss: 0.4244 - val_accuracy: 0.8555\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 333s 2s/step - loss: 0.2873 - accuracy: 0.8915 - val_loss: 0.4323 - val_accuracy: 0.8575\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.2808 - accuracy: 0.8929 - val_loss: 0.4285 - val_accuracy: 0.8543\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 331s 2s/step - loss: 0.2816 - accuracy: 0.8903 - val_loss: 0.4382 - val_accuracy: 0.8602\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.2674 - accuracy: 0.8969 - val_loss: 0.4441 - val_accuracy: 0.8537\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 328s 2s/step - loss: 0.2562 - accuracy: 0.9002 - val_loss: 0.4337 - val_accuracy: 0.8587\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 328s 2s/step - loss: 0.2512 - accuracy: 0.9017 - val_loss: 0.4703 - val_accuracy: 0.8610\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.2429 - accuracy: 0.9077 - val_loss: 0.4506 - val_accuracy: 0.8630\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.2164 - accuracy: 0.9172 - val_loss: 0.4841 - val_accuracy: 0.8543\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 331s 2s/step - loss: 0.2176 - accuracy: 0.9146 - val_loss: 0.4988 - val_accuracy: 0.8530\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 331s 2s/step - loss: 0.2046 - accuracy: 0.9215 - val_loss: 0.4910 - val_accuracy: 0.8580\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.1974 - accuracy: 0.9236 - val_loss: 0.5329 - val_accuracy: 0.8493\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 327s 2s/step - loss: 0.1854 - accuracy: 0.9283 - val_loss: 0.5878 - val_accuracy: 0.8435\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 328s 2s/step - loss: 0.1856 - accuracy: 0.9298 - val_loss: 0.5415 - val_accuracy: 0.8478\n",
      "Epoch 45/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.1755 - accuracy: 0.9317 - val_loss: 0.5776 - val_accuracy: 0.8475\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 328s 2s/step - loss: 0.1680 - accuracy: 0.9365 - val_loss: 0.5669 - val_accuracy: 0.8572\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.1565 - accuracy: 0.9410 - val_loss: 0.5781 - val_accuracy: 0.8515\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.1406 - accuracy: 0.9472 - val_loss: 0.6013 - val_accuracy: 0.8508\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 334s 2s/step - loss: 0.1518 - accuracy: 0.9430 - val_loss: 0.5375 - val_accuracy: 0.8572\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 334s 2s/step - loss: 0.1318 - accuracy: 0.9520 - val_loss: 0.6001 - val_accuracy: 0.8490\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.1249 - accuracy: 0.9531 - val_loss: 0.7677 - val_accuracy: 0.8445\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 333s 2s/step - loss: 0.1372 - accuracy: 0.9493 - val_loss: 0.6981 - val_accuracy: 0.8530\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.1228 - accuracy: 0.9556 - val_loss: 0.6755 - val_accuracy: 0.8500\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.1177 - accuracy: 0.9565 - val_loss: 0.6202 - val_accuracy: 0.8550\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 327s 2s/step - loss: 0.1010 - accuracy: 0.9623 - val_loss: 0.6856 - val_accuracy: 0.8558\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.1082 - accuracy: 0.9623 - val_loss: 0.7118 - val_accuracy: 0.8512\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.1092 - accuracy: 0.9596 - val_loss: 0.7326 - val_accuracy: 0.8562\n",
      "Epoch 58/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.1036 - accuracy: 0.9625 - val_loss: 0.7242 - val_accuracy: 0.8525\n",
      "Epoch 59/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.0897 - accuracy: 0.9697 - val_loss: 0.7990 - val_accuracy: 0.8510\n",
      "Epoch 60/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.0939 - accuracy: 0.9665 - val_loss: 0.8089 - val_accuracy: 0.8505\n",
      "Epoch 61/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.1025 - accuracy: 0.9635 - val_loss: 0.7876 - val_accuracy: 0.8485\n",
      "Epoch 62/100\n",
      "157/157 [==============================] - 331s 2s/step - loss: 0.0958 - accuracy: 0.9652 - val_loss: 0.8407 - val_accuracy: 0.8553\n",
      "Epoch 63/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.0814 - accuracy: 0.9717 - val_loss: 0.7820 - val_accuracy: 0.8547\n",
      "Epoch 64/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.0750 - accuracy: 0.9740 - val_loss: 0.7972 - val_accuracy: 0.8583\n",
      "Epoch 65/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.0722 - accuracy: 0.9743 - val_loss: 0.8484 - val_accuracy: 0.8518\n",
      "Epoch 66/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.0883 - accuracy: 0.9693 - val_loss: 0.8440 - val_accuracy: 0.8543\n",
      "Epoch 67/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.0787 - accuracy: 0.9722 - val_loss: 0.8578 - val_accuracy: 0.8503\n",
      "Epoch 68/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.0844 - accuracy: 0.9707 - val_loss: 0.8633 - val_accuracy: 0.8485\n",
      "Epoch 69/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.0854 - accuracy: 0.9701 - val_loss: 0.8795 - val_accuracy: 0.8508\n",
      "Epoch 70/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.0791 - accuracy: 0.9721 - val_loss: 0.8043 - val_accuracy: 0.8535\n",
      "Epoch 71/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.0733 - accuracy: 0.9747 - val_loss: 0.9393 - val_accuracy: 0.8510\n",
      "Epoch 72/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.0677 - accuracy: 0.9759 - val_loss: 0.8652 - val_accuracy: 0.8485\n",
      "Epoch 73/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.0611 - accuracy: 0.9791 - val_loss: 1.0456 - val_accuracy: 0.8482\n",
      "Epoch 74/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.0792 - accuracy: 0.9735 - val_loss: 0.9147 - val_accuracy: 0.8428\n",
      "Epoch 75/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.0628 - accuracy: 0.9789 - val_loss: 0.9139 - val_accuracy: 0.8585\n",
      "Epoch 76/100\n",
      "157/157 [==============================] - 333s 2s/step - loss: 0.0727 - accuracy: 0.9747 - val_loss: 0.8622 - val_accuracy: 0.8505\n",
      "Epoch 77/100\n",
      "157/157 [==============================] - 334s 2s/step - loss: 0.0643 - accuracy: 0.9779 - val_loss: 0.8296 - val_accuracy: 0.8555\n",
      "Epoch 78/100\n",
      "157/157 [==============================] - 339s 2s/step - loss: 0.0657 - accuracy: 0.9768 - val_loss: 0.9558 - val_accuracy: 0.8510\n",
      "Epoch 79/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.0677 - accuracy: 0.9765 - val_loss: 0.9436 - val_accuracy: 0.8410\n",
      "Epoch 80/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.0643 - accuracy: 0.9786 - val_loss: 0.9424 - val_accuracy: 0.8530\n",
      "Epoch 81/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.0705 - accuracy: 0.9769 - val_loss: 1.0183 - val_accuracy: 0.8493\n",
      "Epoch 82/100\n",
      "157/157 [==============================] - 331s 2s/step - loss: 0.0720 - accuracy: 0.9747 - val_loss: 1.0008 - val_accuracy: 0.8530\n",
      "Epoch 83/100\n",
      "157/157 [==============================] - 334s 2s/step - loss: 0.0648 - accuracy: 0.9796 - val_loss: 1.0523 - val_accuracy: 0.8522\n",
      "Epoch 84/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.0716 - accuracy: 0.9761 - val_loss: 0.9620 - val_accuracy: 0.8505\n",
      "Epoch 85/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.0606 - accuracy: 0.9805 - val_loss: 0.8720 - val_accuracy: 0.8515\n",
      "Epoch 86/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.0621 - accuracy: 0.9794 - val_loss: 0.8953 - val_accuracy: 0.8420\n",
      "Epoch 87/100\n",
      "157/157 [==============================] - 335s 2s/step - loss: 0.0564 - accuracy: 0.9823 - val_loss: 0.9561 - val_accuracy: 0.8482\n",
      "Epoch 88/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.0531 - accuracy: 0.9825 - val_loss: 1.0859 - val_accuracy: 0.8413\n",
      "Epoch 89/100\n",
      "157/157 [==============================] - 333s 2s/step - loss: 0.0602 - accuracy: 0.9803 - val_loss: 0.9722 - val_accuracy: 0.8468\n",
      "Epoch 90/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.0432 - accuracy: 0.9862 - val_loss: 1.0851 - val_accuracy: 0.8500\n",
      "Epoch 91/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.0458 - accuracy: 0.9843 - val_loss: 1.0564 - val_accuracy: 0.8485\n",
      "Epoch 92/100\n",
      "157/157 [==============================] - 330s 2s/step - loss: 0.0540 - accuracy: 0.9832 - val_loss: 0.9607 - val_accuracy: 0.8533\n",
      "Epoch 93/100\n",
      "157/157 [==============================] - 329s 2s/step - loss: 0.0535 - accuracy: 0.9826 - val_loss: 1.1014 - val_accuracy: 0.8510\n",
      "Epoch 94/100\n",
      "157/157 [==============================] - 332s 2s/step - loss: 0.0491 - accuracy: 0.9828 - val_loss: 1.1020 - val_accuracy: 0.8500\n",
      "Epoch 95/100\n",
      "157/157 [==============================] - 335s 2s/step - loss: 0.0581 - accuracy: 0.9814 - val_loss: 1.0589 - val_accuracy: 0.8508\n",
      "Epoch 96/100\n",
      "157/157 [==============================] - 337s 2s/step - loss: 0.0476 - accuracy: 0.9854 - val_loss: 0.9796 - val_accuracy: 0.8537\n",
      "Epoch 97/100\n",
      "157/157 [==============================] - 337s 2s/step - loss: 0.0544 - accuracy: 0.9826 - val_loss: 1.0575 - val_accuracy: 0.8487\n",
      "Epoch 98/100\n",
      "157/157 [==============================] - 334s 2s/step - loss: 0.0498 - accuracy: 0.9847 - val_loss: 1.1561 - val_accuracy: 0.8508\n",
      "Epoch 99/100\n",
      "157/157 [==============================] - 336s 2s/step - loss: 0.0490 - accuracy: 0.9844 - val_loss: 1.1652 - val_accuracy: 0.8547\n",
      "Epoch 100/100\n",
      "157/157 [==============================] - 338s 2s/step - loss: 0.0587 - accuracy: 0.9811 - val_loss: 0.9966 - val_accuracy: 0.8508\n"
     ]
    }
   ],
   "source": [
    "fe.train(x_train, y_train, x_test, y_test,\n",
    "                 epochs=100,\n",
    "                 batch_size=128,\n",
    "                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1af6f9090588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'extractor.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'extractor-model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Model saved!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-670743fc7363>\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, model_file, encoder_model_file)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "fe.save('extractor.h5', 'extractor-model.h5')\n",
    "print (\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
